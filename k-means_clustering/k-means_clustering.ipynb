{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ccf7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "pd.reset_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4faf4e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(12.)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "x = torch.Tensor([1, 2, 3])\n",
    "x\n",
    "y = torch.Tensor([3, 4, 5])\n",
    "z = (y - x) ** 2\n",
    "z\n",
    "z.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636e9ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(6747, 132)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = pd.read_excel(r'./input/feature.xls')\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf7993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Leq_mean', 'Leq_var', 'Leq_std', 'Leq_max', 'Leq_10', 'Leq_25',\n       'Leq_median', 'Leq_75', 'Leq_90', 'Leq_10-Leq_90',\n       ...\n       'sharpness_deviation2', 'tonality_tmax', 'tonality_phimax',\n       'tonality_w', 'tonality_te', 'tonality_emd', 'tonality_esm',\n       'tonality_slop1', 'tonality_slop2', 'tonality_deviation1'],\n      dtype='object', length=121)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract effective feature\n",
    "col = feature.columns[10:-1]\n",
    "col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c99a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   Leq_mean  Leq_var  Leq_std  Leq_max  Leq_10  Leq_25  Leq_median  Leq_75  \\\n0     49.88     1.93     1.39    54.25   48.18   48.84       49.75   50.67   \n1     49.71     2.68     1.64    54.70   47.90   48.37       49.31   50.83   \n2     50.53     9.36     3.06    55.87   46.26   48.45       51.20   52.79   \n3     49.96    13.89     3.73    57.87   45.00   46.82       50.18   52.87   \n4     50.51     3.25     1.80    58.05   48.56   49.16       50.09   51.52   \n\n   Leq_90  Leq_10-Leq_90  ...  sharpness_deviation2  tonality_tmax  \\\n0   51.74          -3.56  ...               0.22449        1.48699   \n1   52.21          -4.31  ...               0.34575        4.50743   \n2   53.95          -7.69  ...               0.35291        9.47955   \n3   55.17         -10.17  ...               0.27142        0.46468   \n4   52.70          -4.14  ...               0.14822        1.20818   \n\n   tonality_phimax  tonality_w  tonality_te  tonality_emd  tonality_esm  \\\n0          0.12229     0.04647      3.34572       0.01873       0.75760   \n1          0.11179     0.04647     13.66171       0.02127       0.76335   \n2          0.08939     0.13941      5.15799       0.01710       0.68687   \n3          0.08878     0.04647     11.94238       0.02049       0.76139   \n4          0.11093     0.04647     15.84572       0.02380       0.79167   \n\n   tonality_slop1  tonality_slop2  tonality_deviation1  \n0        -0.28448        -0.41390              0.37501  \n1         0.68212        -0.54530              0.11233  \n2         0.09005        -0.88356              0.02650  \n3         0.13123        -0.13545              0.07406  \n4        -0.78949        -0.07725              0.23485  \n\n[5 rows x 121 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Leq_mean</th>\n      <th>Leq_var</th>\n      <th>Leq_std</th>\n      <th>Leq_max</th>\n      <th>Leq_10</th>\n      <th>Leq_25</th>\n      <th>Leq_median</th>\n      <th>Leq_75</th>\n      <th>Leq_90</th>\n      <th>Leq_10-Leq_90</th>\n      <th>...</th>\n      <th>sharpness_deviation2</th>\n      <th>tonality_tmax</th>\n      <th>tonality_phimax</th>\n      <th>tonality_w</th>\n      <th>tonality_te</th>\n      <th>tonality_emd</th>\n      <th>tonality_esm</th>\n      <th>tonality_slop1</th>\n      <th>tonality_slop2</th>\n      <th>tonality_deviation1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49.88</td>\n      <td>1.93</td>\n      <td>1.39</td>\n      <td>54.25</td>\n      <td>48.18</td>\n      <td>48.84</td>\n      <td>49.75</td>\n      <td>50.67</td>\n      <td>51.74</td>\n      <td>-3.56</td>\n      <td>...</td>\n      <td>0.22449</td>\n      <td>1.48699</td>\n      <td>0.12229</td>\n      <td>0.04647</td>\n      <td>3.34572</td>\n      <td>0.01873</td>\n      <td>0.75760</td>\n      <td>-0.28448</td>\n      <td>-0.41390</td>\n      <td>0.37501</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49.71</td>\n      <td>2.68</td>\n      <td>1.64</td>\n      <td>54.70</td>\n      <td>47.90</td>\n      <td>48.37</td>\n      <td>49.31</td>\n      <td>50.83</td>\n      <td>52.21</td>\n      <td>-4.31</td>\n      <td>...</td>\n      <td>0.34575</td>\n      <td>4.50743</td>\n      <td>0.11179</td>\n      <td>0.04647</td>\n      <td>13.66171</td>\n      <td>0.02127</td>\n      <td>0.76335</td>\n      <td>0.68212</td>\n      <td>-0.54530</td>\n      <td>0.11233</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50.53</td>\n      <td>9.36</td>\n      <td>3.06</td>\n      <td>55.87</td>\n      <td>46.26</td>\n      <td>48.45</td>\n      <td>51.20</td>\n      <td>52.79</td>\n      <td>53.95</td>\n      <td>-7.69</td>\n      <td>...</td>\n      <td>0.35291</td>\n      <td>9.47955</td>\n      <td>0.08939</td>\n      <td>0.13941</td>\n      <td>5.15799</td>\n      <td>0.01710</td>\n      <td>0.68687</td>\n      <td>0.09005</td>\n      <td>-0.88356</td>\n      <td>0.02650</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49.96</td>\n      <td>13.89</td>\n      <td>3.73</td>\n      <td>57.87</td>\n      <td>45.00</td>\n      <td>46.82</td>\n      <td>50.18</td>\n      <td>52.87</td>\n      <td>55.17</td>\n      <td>-10.17</td>\n      <td>...</td>\n      <td>0.27142</td>\n      <td>0.46468</td>\n      <td>0.08878</td>\n      <td>0.04647</td>\n      <td>11.94238</td>\n      <td>0.02049</td>\n      <td>0.76139</td>\n      <td>0.13123</td>\n      <td>-0.13545</td>\n      <td>0.07406</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50.51</td>\n      <td>3.25</td>\n      <td>1.80</td>\n      <td>58.05</td>\n      <td>48.56</td>\n      <td>49.16</td>\n      <td>50.09</td>\n      <td>51.52</td>\n      <td>52.70</td>\n      <td>-4.14</td>\n      <td>...</td>\n      <td>0.14822</td>\n      <td>1.20818</td>\n      <td>0.11093</td>\n      <td>0.04647</td>\n      <td>15.84572</td>\n      <td>0.02380</td>\n      <td>0.79167</td>\n      <td>-0.78949</td>\n      <td>-0.07725</td>\n      <td>0.23485</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 121 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_use = feature[col]\n",
    "feature_use.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d554b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance\n",
    "def distEu(x, y):\n",
    "    sum = np.sqrt(np.sum((x - y) ** 2))\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec34ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A set of K random centers of mass\n",
    "def randCenter(dataSet, k):\n",
    "    # m represents row\n",
    "    # n represents col\n",
    "    m, n = dataSet.shape\n",
    "\n",
    "    # initialize center\n",
    "    centroid = np.zeros((k, n))\n",
    "    centroid = pd.DataFrame(centroid)\n",
    "\n",
    "    # traverse\n",
    "    for i in range(k):\n",
    "        # index为0-m之间的随机整数\n",
    "        index = int(np.random.uniform(0, m))\n",
    "        # calculate centroid and assign \n",
    "        centroid.iloc[i, :] = dataSet.iloc[index, :]\n",
    "    return centroid\n",
    "\n",
    "\n",
    "# k-means clustering\n",
    "# k-means clustering\n",
    "def KMeans(dataSet, k):\n",
    "    m = np.shape(dataSet)[0]\n",
    "\n",
    "    # 初始化一个矩阵来储存每个点的簇分配结果\n",
    "    # clusterAssment包含两列：1列记录簇索引值，2列存储当前点到簇质心的距离（用来评价聚类的效果）\n",
    "    clusterAssment = np.mat(np.zeros((m, 2)))\n",
    "    clusterChange = True\n",
    "\n",
    "    # 创建质心\n",
    "    centroid = randCenter(dataSet, k)\n",
    "    # 初始化标志变量，用于判断迭代是否继续，如果True，则迭代继续\n",
    "    while clusterChange:\n",
    "        clusterChange = False\n",
    "\n",
    "        # 遍历所有行\n",
    "        for i in range(m):\n",
    "            minDist = 10000\n",
    "            minIndex = -1\n",
    "            # 遍历所有点找到距离每个点最近的质心\n",
    "            for j in range(k):\n",
    "                dist = distEu(centroid.iloc[j, :], dataSet.iloc[i, :])\n",
    "                # 如果距离小于minDist，更新minDist和index索引值\n",
    "                if dist < minDist:\n",
    "                    minDist = dist\n",
    "                    minIndex = j\n",
    "            # 如果任意一点的簇分配结果发生改变，则更新clusterChanged标志\n",
    "            if clusterAssment[i, 0] != minIndex:\n",
    "                clusterChange = True\n",
    "                # 更新簇分配结果为最小质心的index，minDist\n",
    "                clusterAssment[i, :] = minIndex, minDist\n",
    "\n",
    "        # 遍历所有质心并更新他们的取值\n",
    "        for j in range(k):\n",
    "            # 通过数据过滤来过的给定簇的所有点\n",
    "            # .A表示把矩阵转化为array的形式\n",
    "            # pointsInCluster = dataSet[np.nonzero(clusterAssment[:, 0].A == j)[0]]\n",
    "            clusterAssment = pd.DataFrame(clusterAssment)\n",
    "            same_cluster_index = clusterAssment.iloc[:, 0].isin([j])\n",
    "            pointsInCluster = dataSet[same_cluster_index]\n",
    "\n",
    "            # 计算所有点的均值，axis=0表示沿着列方向进行均值\n",
    "            centroid.iloc[j, :] = np.mean(pointsInCluster, axis=0)\n",
    "    print(\"Cluster complete!\")\n",
    "    return centroid, clusterAssment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d556783f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4\u001B[39m\n\u001B[0;32m      2\u001B[0m feature_test \u001B[38;5;241m=\u001B[39m feature_use\u001B[38;5;241m.\u001B[39miloc[:\u001B[38;5;241m20\u001B[39m]\n\u001B[1;32m----> 3\u001B[0m centroids, clusterAssment \u001B[38;5;241m=\u001B[39m \u001B[43mKMeans\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36mKMeans\u001B[1;34m(dataSet, k)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# 遍历所有行\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(m):\n\u001B[1;32m---> 38\u001B[0m     minDist \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10000\u001B[39m\n\u001B[0;32m     39\u001B[0m     minIndex \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m# 遍历所有点找到距离每个点最近的质心\u001B[39;00m\n",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36mKMeans\u001B[1;34m(dataSet, k)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# 遍历所有行\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(m):\n\u001B[1;32m---> 38\u001B[0m     minDist \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10000\u001B[39m\n\u001B[0;32m     39\u001B[0m     minIndex \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m# 遍历所有点找到距离每个点最近的质心\u001B[39;00m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1180\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:621\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1096\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1058\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:318\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Programming\\IDE\\PyCharm 2021.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Programming\\IDE\\PyCharm 2021.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "feature_test = feature_use.iloc[:20]\n",
    "centroids, clusterAssment = KMeans(feature_test, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "       0        1       2       3        4       5        6       7      8    \\\n0  54.1605  14.6675  3.0255  63.154  50.6615  51.873  53.8235  56.077  58.11   \n1      NaN      NaN     NaN     NaN      NaN     NaN      NaN     NaN    NaN   \n2      NaN      NaN     NaN     NaN      NaN     NaN      NaN     NaN    NaN   \n3      NaN      NaN     NaN     NaN      NaN     NaN      NaN     NaN    NaN   \n\n      9    ...       111      112       113       114        115       116  \\\n0 -7.4485  ...  0.260277  4.36803  0.122435  0.123143  10.230018  0.020287   \n1     NaN  ...       NaN      NaN       NaN       NaN        NaN       NaN   \n2     NaN  ...       NaN      NaN       NaN       NaN        NaN       NaN   \n3     NaN  ...       NaN      NaN       NaN       NaN        NaN       NaN   \n\n        117      118       119       120  \n0  0.756458 -0.58334 -0.537472  0.215828  \n1       NaN      NaN       NaN       NaN  \n2       NaN      NaN       NaN       NaN  \n3       NaN      NaN       NaN       NaN  \n\n[4 rows x 121 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>111</th>\n      <th>112</th>\n      <th>113</th>\n      <th>114</th>\n      <th>115</th>\n      <th>116</th>\n      <th>117</th>\n      <th>118</th>\n      <th>119</th>\n      <th>120</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>54.1605</td>\n      <td>14.6675</td>\n      <td>3.0255</td>\n      <td>63.154</td>\n      <td>50.6615</td>\n      <td>51.873</td>\n      <td>53.8235</td>\n      <td>56.077</td>\n      <td>58.11</td>\n      <td>-7.4485</td>\n      <td>...</td>\n      <td>0.260277</td>\n      <td>4.36803</td>\n      <td>0.122435</td>\n      <td>0.123143</td>\n      <td>10.230018</td>\n      <td>0.020287</td>\n      <td>0.756458</td>\n      <td>-0.58334</td>\n      <td>-0.537472</td>\n      <td>0.215828</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 121 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389f5612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(matrix([[0., 0.],\n         [1., 1.],\n         [1., 2.]]),\n array([[False],\n        [ True],\n        [ True]]),\n (array([1, 2], dtype=int64), array([0, 0], dtype=int64)))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.mat(np.zeros((3, 2)))\n",
    "b = np.ones((3, 2))\n",
    "a, b\n",
    "a[2, :] = 1, 2\n",
    "a\n",
    "a.A\n",
    "\n",
    "a[1, :] = b[2, :]\n",
    "a\n",
    "\n",
    "a, a[:, 0].A == 1, np.nonzero(a[:, 0].A == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "np.nonzero?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(     0    1\n 0  0.0  0.0\n 1  1.0  1.0\n 2  1.0  2.0,\n 0    False\n 1     True\n 2     True\n Name: 0, dtype: bool,\n      0    1\n 1  1.0  1.0\n 2  1.0  2.0)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = np.array([[True, False, True], [True, False, False]])\n",
    "np.nonzero(b2)\n",
    "\n",
    "a.astype(int)\n",
    "a = pd.DataFrame(a)\n",
    "flag = a.iloc[:, 0].isin([1])\n",
    "a, flag, a[flag]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function nonzero in module numpy:\n",
      "\n",
      "nonzero(a)\n",
      "    Return the indices of the elements that are non-zero.\n",
      "    \n",
      "    Returns a tuple of arrays, one for each dimension of `a`,\n",
      "    containing the indices of the non-zero elements in that\n",
      "    dimension. The values in `a` are always tested and returned in\n",
      "    row-major, C-style order.\n",
      "    \n",
      "    To group the indices by element, rather than dimension, use `argwhere`,\n",
      "    which returns a row for each non-zero element.\n",
      "    \n",
      "    .. note::\n",
      "    \n",
      "       When called on a zero-d array or scalar, ``nonzero(a)`` is treated\n",
      "       as ``nonzero(atleast_1d(a))``.\n",
      "    \n",
      "       .. deprecated:: 1.17.0\n",
      "    \n",
      "          Use `atleast_1d` explicitly if this behavior is deliberate.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Input array.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    tuple_of_arrays : tuple\n",
      "        Indices of elements that are non-zero.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    flatnonzero :\n",
      "        Return indices that are non-zero in the flattened version of the input\n",
      "        array.\n",
      "    ndarray.nonzero :\n",
      "        Equivalent ndarray method.\n",
      "    count_nonzero :\n",
      "        Counts the number of non-zero elements in the input array.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    While the nonzero values can be obtained with ``a[nonzero(a)]``, it is\n",
      "    recommended to use ``x[x.astype(bool)]`` or ``x[x != 0]`` instead, which\n",
      "    will correctly handle 0-d arrays.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.array([[3, 0, 0], [0, 4, 0], [5, 6, 0]])\n",
      "    >>> x\n",
      "    array([[3, 0, 0],\n",
      "           [0, 4, 0],\n",
      "           [5, 6, 0]])\n",
      "    >>> np.nonzero(x)\n",
      "    (array([0, 1, 2, 2]), array([0, 1, 0, 1]))\n",
      "    \n",
      "    >>> x[np.nonzero(x)]\n",
      "    array([3, 4, 5, 6])\n",
      "    >>> np.transpose(np.nonzero(x))\n",
      "    array([[0, 0],\n",
      "           [1, 1],\n",
      "           [2, 0],\n",
      "           [2, 1]])\n",
      "    \n",
      "    A common use for ``nonzero`` is to find the indices of an array, where\n",
      "    a condition is True.  Given an array `a`, the condition `a` > 3 is a\n",
      "    boolean array and since False is interpreted as 0, np.nonzero(a > 3)\n",
      "    yields the indices of the `a` where the condition is true.\n",
      "    \n",
      "    >>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "    >>> a > 3\n",
      "    array([[False, False, False],\n",
      "           [ True,  True,  True],\n",
      "           [ True,  True,  True]])\n",
      "    >>> np.nonzero(a > 3)\n",
      "    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))\n",
      "    \n",
      "    Using this result to index `a` is equivalent to using the mask directly:\n",
      "    \n",
      "    >>> a[np.nonzero(a > 3)]\n",
      "    array([4, 5, 6, 7, 8, 9])\n",
      "    >>> a[a > 3]  # prefer this spelling\n",
      "    array([4, 5, 6, 7, 8, 9])\n",
      "    \n",
      "    ``nonzero`` can also be called as a method of the array.\n",
      "    \n",
      "    >>> (a > 3).nonzero()\n",
      "    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.nonzero)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "     0    1    2    3\n0  0.0  0.0  0.0  0.0\n1  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((3,4))\n",
    "a\n",
    "a= pd.DataFrame(a)\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "   0\n",
      "0  3\n",
      "1  4\n",
      "2  5\n"
     ]
    },
    {
     "data": {
      "text/plain": "0    3.464102\ndtype: float64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame([1,2,3])\n",
    "y = pd.DataFrame([3,4,5])\n",
    "print(x)\n",
    "print(y)\n",
    "sum = np.sqrt(np.sum((x - y) ** 2))\n",
    "sum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 122.47448713915891)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def distEu(x, y):\n",
    "    sum = np.sqrt(np.sum((x - y) ** 2))\n",
    "    return sum\n",
    "\n",
    "b = np.ones(15000)\n",
    "c = np.zeros(15000)\n",
    "\n",
    "import time\n",
    "tic = time.time()*100000000\n",
    "c = distEu(b, c)\n",
    "toc = time.time()*100000000\n",
    "toc - tic, c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function concat in module pandas.core.reshape.concat:\n",
      "\n",
      "concat(objs: Union[Iterable[ForwardRef('NDFrame')], Mapping[Optional[Hashable], ForwardRef('NDFrame')]], axis=0, join='outer', ignore_index: bool = False, keys=None, levels=None, names=None, verify_integrity: bool = False, sort: bool = False, copy: bool = True) -> Union[ForwardRef('DataFrame'), ForwardRef('Series')]\n",
      "    Concatenate pandas objects along a particular axis with optional set logic\n",
      "    along the other axes.\n",
      "    \n",
      "    Can also add a layer of hierarchical indexing on the concatenation axis,\n",
      "    which may be useful if the labels are the same (or overlapping) on\n",
      "    the passed axis number.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    objs : a sequence or mapping of Series or DataFrame objects\n",
      "        If a mapping is passed, the sorted keys will be used as the `keys`\n",
      "        argument, unless it is passed, in which case the values will be\n",
      "        selected (see below). Any None objects will be dropped silently unless\n",
      "        they are all None in which case a ValueError will be raised.\n",
      "    axis : {0/'index', 1/'columns'}, default 0\n",
      "        The axis to concatenate along.\n",
      "    join : {'inner', 'outer'}, default 'outer'\n",
      "        How to handle indexes on other axis (or axes).\n",
      "    ignore_index : bool, default False\n",
      "        If True, do not use the index values along the concatenation axis. The\n",
      "        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
      "        concatenating objects where the concatenation axis does not have\n",
      "        meaningful indexing information. Note the index values on the other\n",
      "        axes are still respected in the join.\n",
      "    keys : sequence, default None\n",
      "        If multiple levels passed, should contain tuples. Construct\n",
      "        hierarchical index using the passed keys as the outermost level.\n",
      "    levels : list of sequences, default None\n",
      "        Specific levels (unique values) to use for constructing a\n",
      "        MultiIndex. Otherwise they will be inferred from the keys.\n",
      "    names : list, default None\n",
      "        Names for the levels in the resulting hierarchical index.\n",
      "    verify_integrity : bool, default False\n",
      "        Check whether the new concatenated axis contains duplicates. This can\n",
      "        be very expensive relative to the actual data concatenation.\n",
      "    sort : bool, default False\n",
      "        Sort non-concatenation axis if it is not already aligned when `join`\n",
      "        is 'outer'.\n",
      "        This has no effect when ``join='inner'``, which already preserves\n",
      "        the order of the non-concatenation axis.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           Changed to not sort by default.\n",
      "    \n",
      "    copy : bool, default True\n",
      "        If False, do not copy data unnecessarily.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    object, type of objs\n",
      "        When concatenating all ``Series`` along the index (axis=0), a\n",
      "        ``Series`` is returned. When ``objs`` contains at least one\n",
      "        ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
      "        the columns (axis=1), a ``DataFrame`` is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Series.append : Concatenate Series.\n",
      "    DataFrame.append : Concatenate DataFrames.\n",
      "    DataFrame.join : Join DataFrames using indexes.\n",
      "    DataFrame.merge : Merge DataFrames by indexes or columns.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The keys, levels, and names arguments are all optional.\n",
      "    \n",
      "    A walkthrough of how this method fits in with other tools for combining\n",
      "    pandas objects can be found `here\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Combine two ``Series``.\n",
      "    \n",
      "    >>> s1 = pd.Series(['a', 'b'])\n",
      "    >>> s2 = pd.Series(['c', 'd'])\n",
      "    >>> pd.concat([s1, s2])\n",
      "    0    a\n",
      "    1    b\n",
      "    0    c\n",
      "    1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Clear the existing index and reset it in the result\n",
      "    by setting the ``ignore_index`` option to ``True``.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], ignore_index=True)\n",
      "    0    a\n",
      "    1    b\n",
      "    2    c\n",
      "    3    d\n",
      "    dtype: object\n",
      "    \n",
      "    Add a hierarchical index at the outermost level of\n",
      "    the data with the ``keys`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
      "    s1  0    a\n",
      "        1    b\n",
      "    s2  0    c\n",
      "        1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Label the index keys you create with the ``names`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
      "    ...           names=['Series name', 'Row ID'])\n",
      "    Series name  Row ID\n",
      "    s1           0         a\n",
      "                 1         b\n",
      "    s2           0         c\n",
      "                 1         d\n",
      "    dtype: object\n",
      "    \n",
      "    Combine two ``DataFrame`` objects with identical columns.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df1\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    >>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df2\n",
      "      letter  number\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    >>> pd.concat([df1, df2])\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return everything. Columns outside the intersection will\n",
      "    be filled with ``NaN`` values.\n",
      "    \n",
      "    >>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
      "    ...                    columns=['letter', 'number', 'animal'])\n",
      "    >>> df3\n",
      "      letter  number animal\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    >>> pd.concat([df1, df3], sort=False)\n",
      "      letter  number animal\n",
      "    0      a       1    NaN\n",
      "    1      b       2    NaN\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return only those that are shared by passing ``inner`` to\n",
      "    the ``join`` keyword argument.\n",
      "    \n",
      "    >>> pd.concat([df1, df3], join=\"inner\")\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects horizontally along the x axis by\n",
      "    passing in ``axis=1``.\n",
      "    \n",
      "    >>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
      "    ...                    columns=['animal', 'name'])\n",
      "    >>> pd.concat([df1, df4], axis=1)\n",
      "      letter  number  animal    name\n",
      "    0      a       1    bird   polly\n",
      "    1      b       2  monkey  george\n",
      "    \n",
      "    Prevent the result from including duplicate index values with the\n",
      "    ``verify_integrity`` option.\n",
      "    \n",
      "    >>> df5 = pd.DataFrame([1], index=['a'])\n",
      "    >>> df5\n",
      "       0\n",
      "    a  1\n",
      "    >>> df6 = pd.DataFrame([2], index=['a'])\n",
      "    >>> df6\n",
      "       0\n",
      "    a  2\n",
      "    >>> pd.concat([df5, df6], verify_integrity=True)\n",
      "    Traceback (most recent call last):\n",
      "        ...\n",
      "    ValueError: Indexes have overlapping values: ['a']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.concat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
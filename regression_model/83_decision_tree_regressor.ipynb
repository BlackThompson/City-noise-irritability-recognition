{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset, axis=0)\n",
    "    sigma = np.std(dataset, axis=0)\n",
    "    return (dataset - mu) / sigma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "       声音类别  吵闹度  leq_mean  leq_std    leq_25  leq_median    leq_75  \\\n0         1    4  64.66645  1.56539  63.35437    64.54813  65.57262   \n1         1    4  64.66645  1.56539  63.35437    64.54813  65.57262   \n2         1    6  64.66645  1.56539  63.35437    64.54813  65.57262   \n3         1    4  64.66645  1.56539  63.35437    64.54813  65.57262   \n4         1    7  64.66645  1.56539  63.35437    64.54813  65.57262   \n...     ...  ...       ...      ...       ...         ...       ...   \n20247    83    5  63.90276  1.58277  62.72562    63.50389  65.10709   \n20248    83    9  63.90276  1.58277  62.72562    63.50389  65.10709   \n20249    83    5  63.90276  1.58277  62.72562    63.50389  65.10709   \n20250    83    5  63.90276  1.58277  62.72562    63.50389  65.10709   \n20251    83    5  63.90276  1.58277  62.72562    63.50389  65.10709   \n\n       leq_10_90  loudness_mean  loudness_std  ...  fluct_25  fluct_median  \\\n0        4.14383       17.75490       1.86917  ...   0.00783       0.01473   \n1        4.14383       17.75490       1.86917  ...   0.00783       0.01473   \n2        4.14383       17.75490       1.86917  ...   0.00783       0.01473   \n3        4.14383       17.75490       1.86917  ...   0.00783       0.01473   \n4        4.14383       17.75490       1.86917  ...   0.00783       0.01473   \n...          ...            ...           ...  ...       ...           ...   \n20247    4.15885       16.14553       1.19750  ...   0.00794       0.00967   \n20248    4.15885       16.14553       1.19750  ...   0.00794       0.00967   \n20249    4.15885       16.14553       1.19750  ...   0.00794       0.00967   \n20250    4.15885       16.14553       1.19750  ...   0.00794       0.00967   \n20251    4.15885       16.14553       1.19750  ...   0.00794       0.00967   \n\n       fluct_75  fluct_10_90  tonality_mean  tonality_std  tonality_25  \\\n0       0.01984      0.06271        0.05675       0.04170      0.02823   \n1       0.01984      0.06271        0.05675       0.04170      0.02823   \n2       0.01984      0.06271        0.05675       0.04170      0.02823   \n3       0.01984      0.06271        0.05675       0.04170      0.02823   \n4       0.01984      0.06271        0.05675       0.04170      0.02823   \n...         ...          ...            ...           ...          ...   \n20247   0.02265      0.06929        0.02446       0.02661      0.00000   \n20248   0.02265      0.06929        0.02446       0.02661      0.00000   \n20249   0.02265      0.06929        0.02446       0.02661      0.00000   \n20250   0.02265      0.06929        0.02446       0.02661      0.00000   \n20251   0.02265      0.06929        0.02446       0.02661      0.00000   \n\n       tonality_median  tonality_75  tonality_10_90  \n0              0.05316      0.08016         0.11041  \n1              0.05316      0.08016         0.11041  \n2              0.05316      0.08016         0.11041  \n3              0.05316      0.08016         0.11041  \n4              0.05316      0.08016         0.11041  \n...                ...          ...             ...  \n20247          0.02622      0.04394         0.05603  \n20248          0.02622      0.04394         0.05603  \n20249          0.02622      0.04394         0.05603  \n20250          0.02622      0.04394         0.05603  \n20251          0.02622      0.04394         0.05603  \n\n[20252 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>声音类别</th>\n      <th>吵闹度</th>\n      <th>leq_mean</th>\n      <th>leq_std</th>\n      <th>leq_25</th>\n      <th>leq_median</th>\n      <th>leq_75</th>\n      <th>leq_10_90</th>\n      <th>loudness_mean</th>\n      <th>loudness_std</th>\n      <th>...</th>\n      <th>fluct_25</th>\n      <th>fluct_median</th>\n      <th>fluct_75</th>\n      <th>fluct_10_90</th>\n      <th>tonality_mean</th>\n      <th>tonality_std</th>\n      <th>tonality_25</th>\n      <th>tonality_median</th>\n      <th>tonality_75</th>\n      <th>tonality_10_90</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>4</td>\n      <td>64.66645</td>\n      <td>1.56539</td>\n      <td>63.35437</td>\n      <td>64.54813</td>\n      <td>65.57262</td>\n      <td>4.14383</td>\n      <td>17.75490</td>\n      <td>1.86917</td>\n      <td>...</td>\n      <td>0.00783</td>\n      <td>0.01473</td>\n      <td>0.01984</td>\n      <td>0.06271</td>\n      <td>0.05675</td>\n      <td>0.04170</td>\n      <td>0.02823</td>\n      <td>0.05316</td>\n      <td>0.08016</td>\n      <td>0.11041</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4</td>\n      <td>64.66645</td>\n      <td>1.56539</td>\n      <td>63.35437</td>\n      <td>64.54813</td>\n      <td>65.57262</td>\n      <td>4.14383</td>\n      <td>17.75490</td>\n      <td>1.86917</td>\n      <td>...</td>\n      <td>0.00783</td>\n      <td>0.01473</td>\n      <td>0.01984</td>\n      <td>0.06271</td>\n      <td>0.05675</td>\n      <td>0.04170</td>\n      <td>0.02823</td>\n      <td>0.05316</td>\n      <td>0.08016</td>\n      <td>0.11041</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>64.66645</td>\n      <td>1.56539</td>\n      <td>63.35437</td>\n      <td>64.54813</td>\n      <td>65.57262</td>\n      <td>4.14383</td>\n      <td>17.75490</td>\n      <td>1.86917</td>\n      <td>...</td>\n      <td>0.00783</td>\n      <td>0.01473</td>\n      <td>0.01984</td>\n      <td>0.06271</td>\n      <td>0.05675</td>\n      <td>0.04170</td>\n      <td>0.02823</td>\n      <td>0.05316</td>\n      <td>0.08016</td>\n      <td>0.11041</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>64.66645</td>\n      <td>1.56539</td>\n      <td>63.35437</td>\n      <td>64.54813</td>\n      <td>65.57262</td>\n      <td>4.14383</td>\n      <td>17.75490</td>\n      <td>1.86917</td>\n      <td>...</td>\n      <td>0.00783</td>\n      <td>0.01473</td>\n      <td>0.01984</td>\n      <td>0.06271</td>\n      <td>0.05675</td>\n      <td>0.04170</td>\n      <td>0.02823</td>\n      <td>0.05316</td>\n      <td>0.08016</td>\n      <td>0.11041</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>7</td>\n      <td>64.66645</td>\n      <td>1.56539</td>\n      <td>63.35437</td>\n      <td>64.54813</td>\n      <td>65.57262</td>\n      <td>4.14383</td>\n      <td>17.75490</td>\n      <td>1.86917</td>\n      <td>...</td>\n      <td>0.00783</td>\n      <td>0.01473</td>\n      <td>0.01984</td>\n      <td>0.06271</td>\n      <td>0.05675</td>\n      <td>0.04170</td>\n      <td>0.02823</td>\n      <td>0.05316</td>\n      <td>0.08016</td>\n      <td>0.11041</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20247</th>\n      <td>83</td>\n      <td>5</td>\n      <td>63.90276</td>\n      <td>1.58277</td>\n      <td>62.72562</td>\n      <td>63.50389</td>\n      <td>65.10709</td>\n      <td>4.15885</td>\n      <td>16.14553</td>\n      <td>1.19750</td>\n      <td>...</td>\n      <td>0.00794</td>\n      <td>0.00967</td>\n      <td>0.02265</td>\n      <td>0.06929</td>\n      <td>0.02446</td>\n      <td>0.02661</td>\n      <td>0.00000</td>\n      <td>0.02622</td>\n      <td>0.04394</td>\n      <td>0.05603</td>\n    </tr>\n    <tr>\n      <th>20248</th>\n      <td>83</td>\n      <td>9</td>\n      <td>63.90276</td>\n      <td>1.58277</td>\n      <td>62.72562</td>\n      <td>63.50389</td>\n      <td>65.10709</td>\n      <td>4.15885</td>\n      <td>16.14553</td>\n      <td>1.19750</td>\n      <td>...</td>\n      <td>0.00794</td>\n      <td>0.00967</td>\n      <td>0.02265</td>\n      <td>0.06929</td>\n      <td>0.02446</td>\n      <td>0.02661</td>\n      <td>0.00000</td>\n      <td>0.02622</td>\n      <td>0.04394</td>\n      <td>0.05603</td>\n    </tr>\n    <tr>\n      <th>20249</th>\n      <td>83</td>\n      <td>5</td>\n      <td>63.90276</td>\n      <td>1.58277</td>\n      <td>62.72562</td>\n      <td>63.50389</td>\n      <td>65.10709</td>\n      <td>4.15885</td>\n      <td>16.14553</td>\n      <td>1.19750</td>\n      <td>...</td>\n      <td>0.00794</td>\n      <td>0.00967</td>\n      <td>0.02265</td>\n      <td>0.06929</td>\n      <td>0.02446</td>\n      <td>0.02661</td>\n      <td>0.00000</td>\n      <td>0.02622</td>\n      <td>0.04394</td>\n      <td>0.05603</td>\n    </tr>\n    <tr>\n      <th>20250</th>\n      <td>83</td>\n      <td>5</td>\n      <td>63.90276</td>\n      <td>1.58277</td>\n      <td>62.72562</td>\n      <td>63.50389</td>\n      <td>65.10709</td>\n      <td>4.15885</td>\n      <td>16.14553</td>\n      <td>1.19750</td>\n      <td>...</td>\n      <td>0.00794</td>\n      <td>0.00967</td>\n      <td>0.02265</td>\n      <td>0.06929</td>\n      <td>0.02446</td>\n      <td>0.02661</td>\n      <td>0.00000</td>\n      <td>0.02622</td>\n      <td>0.04394</td>\n      <td>0.05603</td>\n    </tr>\n    <tr>\n      <th>20251</th>\n      <td>83</td>\n      <td>5</td>\n      <td>63.90276</td>\n      <td>1.58277</td>\n      <td>62.72562</td>\n      <td>63.50389</td>\n      <td>65.10709</td>\n      <td>4.15885</td>\n      <td>16.14553</td>\n      <td>1.19750</td>\n      <td>...</td>\n      <td>0.00794</td>\n      <td>0.00967</td>\n      <td>0.02265</td>\n      <td>0.06929</td>\n      <td>0.02446</td>\n      <td>0.02661</td>\n      <td>0.00000</td>\n      <td>0.02622</td>\n      <td>0.04394</td>\n      <td>0.05603</td>\n    </tr>\n  </tbody>\n</table>\n<p>20252 rows × 38 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_83 = pd.read_csv(r'./input/use_data_83.csv')\n",
    "feature_test = pd.read_csv(r'./input/kyllin_features.csv')\n",
    "dataset_83"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "     leq_mean   leq_std    leq_25  leq_median    leq_75  leq_10_90  \\\n0    0.703106  1.896349 -1.138361    1.075007  1.525656   1.901986   \n1    1.069754  0.887349  0.205024    1.393969  1.198400   0.973833   \n2   -0.803636  0.280158 -0.832030   -0.632951 -0.365545   0.324927   \n3   -0.934157 -0.148282 -0.753349   -0.765169 -0.724101  -0.131580   \n4   -0.660582  0.939153 -1.387747    0.163164  0.091113   1.047734   \n..        ...       ...       ...         ...       ...        ...   \n751 -1.006389 -1.305682 -0.098082   -0.814090 -1.306235  -1.415195   \n752  1.922183  0.811058  1.755059    2.285535  1.713245   1.030881   \n753 -0.487141 -0.890271  0.067694   -0.358337 -0.767527  -0.956780   \n754  1.187615  1.421234 -0.437757    1.521456  1.685037   1.256172   \n755  1.374615  0.541443  0.832906    1.308859  1.247901   0.656416   \n\n     loudness_mean  loudness_std  loudness_25  loudness_median  ...  fluct_25  \\\n0         0.179816      1.507711    -1.125406        -0.265919  ... -0.304849   \n1         0.028798      0.458626    -0.441247         0.143378  ...  0.047369   \n2        -1.291273     -0.513430    -1.062949        -1.132707  ...  0.008717   \n3        -1.407592     -0.638591    -1.047155        -1.252144  ... -0.056728   \n4        -1.178542     -0.112163    -1.319957        -0.906407  ...  0.039000   \n..             ...           ...          ...              ...  ...       ...   \n751      -0.209850     -0.880445     0.398697        -0.058476  ... -0.461776   \n752       0.883710      0.550240     0.520740         1.247643  ... -0.193537   \n753      -0.075816     -0.787270     0.369263         0.120329  ... -0.509344   \n754       0.756398      0.829700    -0.264643         0.973847  ... -0.485835   \n755       0.645951      0.104681     0.448232         0.768500  ... -0.171421   \n\n     fluct_median  fluct_75  fluct_10_90  tonality_mean  tonality_std  \\\n0       -0.339014 -0.387199    -0.496036      -0.191114      0.146224   \n1       -0.023069 -0.225602    -0.354328       0.304387      0.333878   \n2       -0.137311 -0.196926    -0.390050      -0.037259      0.400641   \n3       -0.130300 -0.299084    -0.497702      -0.474343     -0.129635   \n4        0.048009 -0.119646    -0.350431       0.389340      1.300508   \n..            ...       ...          ...            ...           ...   \n751     -0.534787 -0.624029    -0.675785      -1.129533     -1.268519   \n752     -0.289420 -0.395307    -0.560550       0.393001      0.610272   \n753     -0.464384 -0.239756    -0.055083      -0.375903     -0.259724   \n754     -0.353615 -0.359581    -0.386149      -0.289531     -0.112663   \n755     -0.183456 -0.211468    -0.340432      -0.060871      0.276583   \n\n     tonality_25  tonality_median  tonality_75  tonality_10_90  \n0      -0.311892        -0.181616    -0.035418        0.202681  \n1       0.367525         0.297034     0.338394        0.744875  \n2      -0.085565        -0.104634     0.065806        0.453976  \n3      -0.535270        -0.498400    -0.397805       -0.196208  \n4       0.094064         0.222039     0.448580        1.035681  \n..           ...              ...          ...             ...  \n751    -0.796747        -1.025932    -1.138526       -1.313291  \n752     0.255595         0.413081     0.504777        0.970423  \n753    -0.250744        -0.336213    -0.345521       -0.176695  \n754    -0.110286        -0.311268    -0.257029        0.005008  \n755    -0.111873        -0.095607     0.064618        0.388606  \n\n[756 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>leq_mean</th>\n      <th>leq_std</th>\n      <th>leq_25</th>\n      <th>leq_median</th>\n      <th>leq_75</th>\n      <th>leq_10_90</th>\n      <th>loudness_mean</th>\n      <th>loudness_std</th>\n      <th>loudness_25</th>\n      <th>loudness_median</th>\n      <th>...</th>\n      <th>fluct_25</th>\n      <th>fluct_median</th>\n      <th>fluct_75</th>\n      <th>fluct_10_90</th>\n      <th>tonality_mean</th>\n      <th>tonality_std</th>\n      <th>tonality_25</th>\n      <th>tonality_median</th>\n      <th>tonality_75</th>\n      <th>tonality_10_90</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.703106</td>\n      <td>1.896349</td>\n      <td>-1.138361</td>\n      <td>1.075007</td>\n      <td>1.525656</td>\n      <td>1.901986</td>\n      <td>0.179816</td>\n      <td>1.507711</td>\n      <td>-1.125406</td>\n      <td>-0.265919</td>\n      <td>...</td>\n      <td>-0.304849</td>\n      <td>-0.339014</td>\n      <td>-0.387199</td>\n      <td>-0.496036</td>\n      <td>-0.191114</td>\n      <td>0.146224</td>\n      <td>-0.311892</td>\n      <td>-0.181616</td>\n      <td>-0.035418</td>\n      <td>0.202681</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.069754</td>\n      <td>0.887349</td>\n      <td>0.205024</td>\n      <td>1.393969</td>\n      <td>1.198400</td>\n      <td>0.973833</td>\n      <td>0.028798</td>\n      <td>0.458626</td>\n      <td>-0.441247</td>\n      <td>0.143378</td>\n      <td>...</td>\n      <td>0.047369</td>\n      <td>-0.023069</td>\n      <td>-0.225602</td>\n      <td>-0.354328</td>\n      <td>0.304387</td>\n      <td>0.333878</td>\n      <td>0.367525</td>\n      <td>0.297034</td>\n      <td>0.338394</td>\n      <td>0.744875</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.803636</td>\n      <td>0.280158</td>\n      <td>-0.832030</td>\n      <td>-0.632951</td>\n      <td>-0.365545</td>\n      <td>0.324927</td>\n      <td>-1.291273</td>\n      <td>-0.513430</td>\n      <td>-1.062949</td>\n      <td>-1.132707</td>\n      <td>...</td>\n      <td>0.008717</td>\n      <td>-0.137311</td>\n      <td>-0.196926</td>\n      <td>-0.390050</td>\n      <td>-0.037259</td>\n      <td>0.400641</td>\n      <td>-0.085565</td>\n      <td>-0.104634</td>\n      <td>0.065806</td>\n      <td>0.453976</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.934157</td>\n      <td>-0.148282</td>\n      <td>-0.753349</td>\n      <td>-0.765169</td>\n      <td>-0.724101</td>\n      <td>-0.131580</td>\n      <td>-1.407592</td>\n      <td>-0.638591</td>\n      <td>-1.047155</td>\n      <td>-1.252144</td>\n      <td>...</td>\n      <td>-0.056728</td>\n      <td>-0.130300</td>\n      <td>-0.299084</td>\n      <td>-0.497702</td>\n      <td>-0.474343</td>\n      <td>-0.129635</td>\n      <td>-0.535270</td>\n      <td>-0.498400</td>\n      <td>-0.397805</td>\n      <td>-0.196208</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.660582</td>\n      <td>0.939153</td>\n      <td>-1.387747</td>\n      <td>0.163164</td>\n      <td>0.091113</td>\n      <td>1.047734</td>\n      <td>-1.178542</td>\n      <td>-0.112163</td>\n      <td>-1.319957</td>\n      <td>-0.906407</td>\n      <td>...</td>\n      <td>0.039000</td>\n      <td>0.048009</td>\n      <td>-0.119646</td>\n      <td>-0.350431</td>\n      <td>0.389340</td>\n      <td>1.300508</td>\n      <td>0.094064</td>\n      <td>0.222039</td>\n      <td>0.448580</td>\n      <td>1.035681</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>751</th>\n      <td>-1.006389</td>\n      <td>-1.305682</td>\n      <td>-0.098082</td>\n      <td>-0.814090</td>\n      <td>-1.306235</td>\n      <td>-1.415195</td>\n      <td>-0.209850</td>\n      <td>-0.880445</td>\n      <td>0.398697</td>\n      <td>-0.058476</td>\n      <td>...</td>\n      <td>-0.461776</td>\n      <td>-0.534787</td>\n      <td>-0.624029</td>\n      <td>-0.675785</td>\n      <td>-1.129533</td>\n      <td>-1.268519</td>\n      <td>-0.796747</td>\n      <td>-1.025932</td>\n      <td>-1.138526</td>\n      <td>-1.313291</td>\n    </tr>\n    <tr>\n      <th>752</th>\n      <td>1.922183</td>\n      <td>0.811058</td>\n      <td>1.755059</td>\n      <td>2.285535</td>\n      <td>1.713245</td>\n      <td>1.030881</td>\n      <td>0.883710</td>\n      <td>0.550240</td>\n      <td>0.520740</td>\n      <td>1.247643</td>\n      <td>...</td>\n      <td>-0.193537</td>\n      <td>-0.289420</td>\n      <td>-0.395307</td>\n      <td>-0.560550</td>\n      <td>0.393001</td>\n      <td>0.610272</td>\n      <td>0.255595</td>\n      <td>0.413081</td>\n      <td>0.504777</td>\n      <td>0.970423</td>\n    </tr>\n    <tr>\n      <th>753</th>\n      <td>-0.487141</td>\n      <td>-0.890271</td>\n      <td>0.067694</td>\n      <td>-0.358337</td>\n      <td>-0.767527</td>\n      <td>-0.956780</td>\n      <td>-0.075816</td>\n      <td>-0.787270</td>\n      <td>0.369263</td>\n      <td>0.120329</td>\n      <td>...</td>\n      <td>-0.509344</td>\n      <td>-0.464384</td>\n      <td>-0.239756</td>\n      <td>-0.055083</td>\n      <td>-0.375903</td>\n      <td>-0.259724</td>\n      <td>-0.250744</td>\n      <td>-0.336213</td>\n      <td>-0.345521</td>\n      <td>-0.176695</td>\n    </tr>\n    <tr>\n      <th>754</th>\n      <td>1.187615</td>\n      <td>1.421234</td>\n      <td>-0.437757</td>\n      <td>1.521456</td>\n      <td>1.685037</td>\n      <td>1.256172</td>\n      <td>0.756398</td>\n      <td>0.829700</td>\n      <td>-0.264643</td>\n      <td>0.973847</td>\n      <td>...</td>\n      <td>-0.485835</td>\n      <td>-0.353615</td>\n      <td>-0.359581</td>\n      <td>-0.386149</td>\n      <td>-0.289531</td>\n      <td>-0.112663</td>\n      <td>-0.110286</td>\n      <td>-0.311268</td>\n      <td>-0.257029</td>\n      <td>0.005008</td>\n    </tr>\n    <tr>\n      <th>755</th>\n      <td>1.374615</td>\n      <td>0.541443</td>\n      <td>0.832906</td>\n      <td>1.308859</td>\n      <td>1.247901</td>\n      <td>0.656416</td>\n      <td>0.645951</td>\n      <td>0.104681</td>\n      <td>0.448232</td>\n      <td>0.768500</td>\n      <td>...</td>\n      <td>-0.171421</td>\n      <td>-0.183456</td>\n      <td>-0.211468</td>\n      <td>-0.340432</td>\n      <td>-0.060871</td>\n      <td>0.276583</td>\n      <td>-0.111873</td>\n      <td>-0.095607</td>\n      <td>0.064618</td>\n      <td>0.388606</td>\n    </tr>\n  </tbody>\n</table>\n<p>756 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr_col1 = ['leq_mean', 'leq_std', 'leq_25', 'leq_median',\n",
    "            'leq_75', 'leq_10_90', 'loudness_mean', 'loudness_std',\n",
    "            'loudness_25', 'loudness_median', 'loudness_75',\n",
    "            'loudness_10_90', 'roughness_mean', 'roughness_std',\n",
    "            'roughness_25', 'roughness_median', 'roughness_75',\n",
    "            'roughness_10_90', 'sharpness_mean', 'sharpness_std',\n",
    "            'sharpness_25', 'sharpness_median', 'sharpness_75',\n",
    "            'sharpness_10_90', 'fluct_mean', 'fluct_std', 'fluct_25',\n",
    "            'fluct_median', 'fluct_75', 'fluct_10_90', 'tonality_mean',\n",
    "            'tonality_std', 'tonality_25', 'tonality_median', 'tonality_75',\n",
    "            'tonality_10_90']\n",
    "y = dataset_83['吵闹度']\n",
    "X_primary = dataset_83[xtr_col1]\n",
    "X = feature_normalize(X_primary)\n",
    "X_test = feature_normalize(feature_test[xtr_col1])\n",
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor()"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeRegressor()\n",
    "dtree.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([6.81967213, 4.27868852, 3.78278689, 3.79918033, 4.31967213,\n       3.71311475, 4.94672131, 3.79918033, 3.79918033, 3.79918033,\n       5.25819672, 5.67622951, 5.67622951, 4.20081967, 4.20081967,\n       4.20081967, 4.20081967, 3.79918033, 4.20081967, 4.64754098,\n       6.24180328, 4.6352459 , 5.25819672, 4.20081967, 4.47540984,\n       6.24180328, 4.20081967, 4.20081967, 3.79918033, 4.79508197,\n       6.24180328, 6.20081967, 4.49590164, 5.04098361, 6.70491803,\n       3.79918033, 3.79918033, 3.71311475, 5.67622951, 3.71311475,\n       3.79918033, 3.71311475, 3.78278689, 4.6352459 , 3.8852459 ,\n       6.24180328, 6.24180328, 6.20081967, 3.62704918, 3.66803279,\n       3.62704918, 4.27868852, 4.27868852, 3.79918033, 4.20081967,\n       4.20081967, 4.20081967, 4.49590164, 6.20081967, 4.20081967,\n       5.63934426, 3.79918033, 6.70491803, 6.20081967, 6.20081967,\n       6.20081967, 6.20081967, 6.20081967, 5.24590164, 5.24590164,\n       6.24180328, 6.20081967, 6.20081967, 6.20081967, 6.20081967,\n       6.20081967, 5.24590164, 6.20081967, 6.20081967, 6.20081967,\n       6.24180328, 6.24180328, 6.24180328, 6.24180328, 4.08196721,\n       6.24180328, 6.83196721, 5.12704918, 6.24180328, 4.49590164,\n       6.24180328, 3.71311475, 6.24180328, 4.49590164, 5.12704918,\n       4.49590164, 4.49590164, 6.24180328, 4.49590164, 4.49590164,\n       3.71311475, 4.6352459 , 5.12704918, 4.49590164, 4.49590164,\n       6.20081967, 4.49590164, 4.49590164, 3.78278689, 4.49590164,\n       4.49590164, 4.46311475, 6.24180328, 4.49590164, 4.49590164,\n       4.49590164, 4.49590164, 3.71311475, 4.49590164, 4.49590164,\n       3.71311475, 4.49590164, 4.49590164, 4.49590164, 5.12704918,\n       4.49590164, 4.49590164, 4.49590164, 4.47540984, 3.71311475,\n       3.5       , 4.49590164, 6.20081967, 4.20081967, 3.78278689,\n       3.71311475, 3.71311475, 5.19262295, 3.78278689, 3.8852459 ,\n       3.78278689, 4.31967213, 3.79918033, 5.67622951, 3.79918033,\n       4.27868852, 4.18442623, 4.31967213, 4.27868852, 3.71311475,\n       3.79918033, 4.20081967, 4.49590164, 4.20081967, 4.20081967,\n       3.79918033, 4.6352459 , 5.67622951, 3.79918033, 3.79918033,\n       4.20081967, 3.79918033, 4.20081967, 3.79918033, 4.20081967,\n       3.79918033, 4.20081967, 5.25819672, 4.20081967, 5.25819672,\n       5.04098361, 3.71311475, 3.5       , 3.5       , 5.34016393,\n       4.27459016, 3.79918033, 3.8852459 , 4.27868852, 6.81967213,\n       4.27868852, 4.31967213, 4.94672131, 4.31967213, 6.20081967,\n       3.59836066, 4.31967213, 3.79918033, 5.54918033, 3.5       ,\n       3.78278689, 4.49590164, 3.71311475, 3.71311475, 3.5       ,\n       3.79918033, 6.81967213, 5.04098361, 4.69262295, 4.49590164,\n       4.27868852, 5.24590164, 4.27868852, 4.17213115, 7.1352459 ,\n       5.24590164, 4.18442623, 3.79918033, 3.79918033, 3.4795082 ,\n       3.66803279, 3.71311475, 3.79918033, 3.78278689, 4.31967213,\n       4.47540984, 4.49590164, 3.59836066, 6.24180328, 5.4795082 ,\n       5.24590164, 5.4795082 , 5.4795082 , 5.4795082 , 5.55737705,\n       4.27459016, 3.79918033, 4.27868852, 6.81967213, 4.27868852,\n       4.31967213, 4.20081967, 4.49590164, 4.20081967, 4.20081967,\n       4.20081967, 4.20081967, 3.4795082 , 3.4795082 , 3.4795082 ,\n       3.78278689, 3.71311475, 4.18442623, 5.55737705, 4.49590164,\n       5.25819672, 3.79918033, 3.76229508, 4.27868852, 3.8852459 ,\n       3.93032787, 4.31967213, 4.27868852, 4.27868852, 3.93032787,\n       5.60245902, 4.27868852, 4.18442623, 5.24590164, 3.93032787,\n       5.34016393, 3.78278689, 4.49590164, 4.18442623, 4.31967213,\n       4.69262295, 3.8852459 , 6.70491803, 6.24180328, 4.31967213,\n       6.20081967, 6.70491803, 5.04098361, 3.79918033, 6.81967213,\n       3.78278689, 5.67622951, 6.81967213, 3.2704918 , 3.71311475,\n       6.20081967, 4.20081967, 5.04098361, 4.18442623, 4.94672131,\n       3.71311475, 3.8852459 , 4.27868852, 5.21311475, 7.1352459 ,\n       4.27868852, 4.31967213, 4.27868852, 3.93852459, 6.20081967,\n       6.65163934, 6.20081967, 6.20081967, 6.20081967, 6.20081967,\n       4.79508197, 6.20081967, 5.04098361, 6.20081967, 3.93852459,\n       4.79508197, 5.70491803, 4.20081967, 3.79918033, 4.6352459 ,\n       6.20081967, 5.24590164, 3.93852459, 5.55737705, 3.93852459,\n       5.24590164, 6.11885246, 4.20081967, 3.76229508, 3.79918033,\n       4.20081967, 4.49590164, 3.79918033, 4.49590164, 4.20081967,\n       3.79918033, 4.27868852, 4.27868852, 5.25819672, 4.20081967,\n       4.20081967, 3.59836066, 6.70491803, 4.49590164, 4.31967213,\n       5.24590164, 6.83196721, 5.54918033, 3.78278689, 4.02868852,\n       4.49590164, 3.4795082 , 5.54918033, 5.55737705, 5.54918033,\n       5.54918033, 5.55737705, 4.74180328, 6.83196721, 6.70491803,\n       6.20081967, 6.74590164, 4.27868852, 5.55737705, 6.81967213,\n       5.55737705, 5.54918033, 5.54918033, 5.54918033, 3.93852459,\n       5.54918033, 5.4795082 , 6.70491803, 4.27868852, 6.70491803,\n       6.70491803, 5.54918033, 4.27868852, 3.93032787, 3.79918033,\n       6.24180328, 4.27868852, 4.27868852, 4.27868852, 3.66803279,\n       6.74590164, 4.27868852, 4.27868852, 5.21311475, 4.46311475,\n       4.49590164, 4.27868852, 4.27868852, 6.74590164, 3.66803279,\n       6.74590164, 4.18442623, 5.24590164, 3.4795082 , 3.62704918,\n       5.24590164, 5.24590164, 5.24590164, 5.55737705, 6.11885246,\n       3.93852459, 5.24590164, 5.54918033, 5.24590164, 3.93852459,\n       3.93852459, 5.24590164, 5.24590164, 6.81967213, 6.11885246,\n       6.20081967, 5.54918033, 5.55737705, 5.54918033, 5.54918033,\n       6.11885246, 5.54918033, 5.54918033, 5.24590164, 5.54918033,\n       6.11885246, 5.54918033, 6.11885246, 5.54918033, 6.11885246,\n       5.54918033, 5.54918033, 5.72540984, 5.54918033, 5.54918033,\n       5.54918033, 5.54918033, 5.54918033, 4.74180328, 5.54918033,\n       5.54918033, 5.54918033, 5.54918033, 5.17622951, 5.54918033,\n       5.54918033, 6.11885246, 5.17622951, 4.74180328, 6.11885246,\n       5.17622951, 6.11885246, 5.54918033, 5.17622951, 5.17622951,\n       5.55737705, 5.54918033, 6.11885246, 5.17622951, 5.55737705,\n       5.55737705, 5.55737705, 5.55737705, 5.55737705, 5.55737705,\n       5.54918033, 3.93852459, 5.55737705, 3.93852459, 4.27868852,\n       3.93852459, 3.93852459, 3.93852459, 3.93852459, 3.93852459,\n       5.24590164, 3.93852459, 6.11885246, 3.93852459, 3.93852459,\n       3.93852459, 3.93852459, 6.11885246, 6.70491803, 4.20081967,\n       3.8852459 , 4.46311475, 4.46311475, 3.71311475, 4.46311475,\n       3.78278689, 4.46311475, 4.6352459 , 6.81967213, 4.31967213,\n       6.81967213, 4.49590164, 4.31967213, 3.62704918, 3.79918033,\n       4.18442623, 3.78278689, 3.71311475, 4.31967213, 6.81967213,\n       4.27459016, 6.81967213, 4.49590164, 3.79918033, 3.8852459 ,\n       4.31967213, 4.31967213, 4.31967213, 3.8852459 , 3.78278689,\n       6.81967213, 4.69262295, 3.2704918 , 4.50409836, 3.79918033,\n       3.79918033, 3.79918033, 4.27868852, 5.67622951, 6.81967213,\n       3.78278689, 3.79918033, 6.81967213, 3.79918033, 4.31967213,\n       3.71311475, 3.79918033, 3.79918033, 5.67622951, 4.49590164,\n       3.79918033, 4.18442623, 5.15163934, 3.79918033, 4.18442623,\n       6.81967213, 5.15163934, 3.78278689, 3.78278689, 5.67622951,\n       3.2704918 , 6.81967213, 4.31967213, 3.59836066, 5.60245902,\n       3.8852459 , 5.04098361, 5.19262295, 4.49590164, 3.93032787,\n       3.69672131, 3.78278689, 6.24180328, 3.93852459, 6.70491803,\n       4.18442623, 3.79918033, 5.67622951, 6.70491803, 3.93852459,\n       3.71311475, 3.79918033, 3.79918033, 6.81967213, 5.67622951,\n       6.81967213, 4.31967213, 6.81967213, 6.81967213, 3.79918033,\n       3.66803279, 5.04098361, 3.78278689, 4.27459016, 4.27868852,\n       3.59836066, 4.49590164, 4.46311475, 4.27868852, 4.27868852,\n       4.94672131, 3.79918033, 3.79918033, 6.11885246, 5.04098361,\n       5.55737705, 6.56557377, 5.23360656, 6.70491803, 7.1352459 ,\n       3.79918033, 4.49590164, 6.81967213, 4.47540984, 4.69262295,\n       4.27868852, 3.78278689, 3.76229508, 4.31967213, 4.79508197,\n       4.27868852, 4.20081967, 5.24590164, 6.20081967, 4.47540984,\n       6.81967213, 3.79918033, 3.79918033, 3.79918033, 4.27459016,\n       6.81967213, 4.94672131, 4.20081967, 3.59836066, 4.20081967,\n       3.59836066, 4.49590164, 3.78278689, 4.08196721, 4.20081967,\n       3.79918033, 4.27868852, 6.70491803, 4.20081967, 3.79918033,\n       5.1557377 , 3.78278689, 3.8852459 , 3.66803279, 3.62704918,\n       5.19262295, 4.20081967, 4.49590164, 4.79508197, 4.20081967,\n       3.93852459, 3.2704918 , 4.31967213, 6.11885246, 5.55737705,\n       7.1352459 , 3.93852459, 3.93852459, 4.79508197, 5.70491803,\n       6.11885246, 6.20081967, 3.93852459, 3.93852459, 5.55737705,\n       5.55737705, 5.55737705, 5.55737705, 5.55737705, 5.24590164,\n       5.24590164, 4.20081967, 5.04098361, 3.79918033, 6.65163934,\n       4.49590164, 4.49590164, 3.8852459 , 3.8852459 , 6.24180328,\n       3.59836066, 3.2704918 , 4.27868852, 4.27868852, 4.69262295,\n       4.27868852, 6.81967213, 4.31967213, 4.46311475, 7.1352459 ,\n       6.70491803, 4.18442623, 3.2704918 , 7.1352459 , 3.93032787,\n       6.24180328, 6.24180328, 3.59836066, 6.65163934, 4.02868852,\n       4.69262295, 6.20081967, 4.18442623, 4.27868852, 3.59836066,\n       3.8852459 , 3.59836066, 6.70491803, 5.15163934, 3.93852459,\n       6.04098361, 3.59836066, 6.11885246, 3.93852459, 4.18442623,\n       4.27868852, 4.31967213, 6.81967213, 4.20081967, 4.27868852,\n       6.20081967, 4.27868852, 3.8852459 , 3.8852459 , 6.04098361,\n       3.59836066, 3.59836066, 3.59836066, 6.20081967, 6.24180328,\n       5.19262295, 4.49590164, 6.81967213, 3.59836066, 3.59836066,\n       4.31967213, 4.27459016, 5.19262295, 3.66803279, 4.79508197,\n       5.17622951, 4.79508197, 4.27868852, 4.94672131, 3.79918033,\n       5.24590164, 4.20081967, 4.20081967, 4.20081967, 4.20081967,\n       4.20081967, 4.20081967, 5.24590164, 3.93852459, 4.20081967,\n       4.20081967, 6.20081967, 4.79508197, 5.24590164, 5.54918033,\n       6.11885246, 6.11885246, 3.93852459, 6.11885246, 5.24590164,\n       6.11885246, 6.11885246, 4.27868852, 4.27459016, 6.11885246,\n       6.11885246, 6.11885246, 4.27868852, 5.04918033, 5.15163934,\n       5.15163934])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = dtree.predict(X_test)\n",
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "7.135245901639344"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "test_out = pd.DataFrame()\n",
    "test_out['name'] = feature_test['name']\n",
    "test_out['score'] = y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "                 name     score\n0     Record85823.xls  6.819672\n1     Record85826.xls  4.278689\n2     Record85828.xls  3.782787\n3     Record85897.xls  3.799180\n4     Record85955.xls  4.319672\n..                ...       ...\n751  Record109726.xls  6.118852\n752  Record109758.xls  4.278689\n753  Record109784.xls  5.049180\n754  Record109802.xls  5.151639\n755  Record109808.xls  5.151639\n\n[756 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Record85823.xls</td>\n      <td>6.819672</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Record85826.xls</td>\n      <td>4.278689</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Record85828.xls</td>\n      <td>3.782787</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Record85897.xls</td>\n      <td>3.799180</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Record85955.xls</td>\n      <td>4.319672</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>751</th>\n      <td>Record109726.xls</td>\n      <td>6.118852</td>\n    </tr>\n    <tr>\n      <th>752</th>\n      <td>Record109758.xls</td>\n      <td>4.278689</td>\n    </tr>\n    <tr>\n      <th>753</th>\n      <td>Record109784.xls</td>\n      <td>5.049180</td>\n    </tr>\n    <tr>\n      <th>754</th>\n      <td>Record109802.xls</td>\n      <td>5.151639</td>\n    </tr>\n    <tr>\n      <th>755</th>\n      <td>Record109808.xls</td>\n      <td>5.151639</td>\n    </tr>\n  </tbody>\n</table>\n<p>756 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "test_out.to_csv(r'./output/test.csv', index=False, encoding='utf_8_sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
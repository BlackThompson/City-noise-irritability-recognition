{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from config import *\n",
    "from cal_accuracy import *\n",
    "\n",
    "# 5 -- 0.72 目前来说最好的\n",
    "#\n",
    "np.random.seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset, axis=0)\n",
    "    sigma = np.std(dataset, axis=0)\n",
    "    return (dataset - mu) / sigma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "data": {
      "text/plain": "       声音类别  吵闹度   leq_mean   leq_var   leq_std    leq_max     leq_10  \\\n0         1    4  64.666450  2.449020  1.565390  68.816510  62.728380   \n1         1    4  64.666450  2.449020  1.565390  68.816510  62.728380   \n2         1    6  64.666450  2.449020  1.565390  68.816510  62.728380   \n3         1    4  64.666450  2.449020  1.565390  68.816510  62.728380   \n4         1    7  64.666450  2.449020  1.565390  68.816510  62.728380   \n...     ...  ...        ...       ...       ...        ...        ...   \n24104     5    2  51.990823  5.154603  2.270476  61.933868  49.136837   \n24105     5    2  51.990823  5.154603  2.270476  61.933868  49.136837   \n24106     5    3  51.990823  5.154603  2.270476  61.933868  49.136837   \n24107     5    5  51.990823  5.154603  2.270476  61.933868  49.136837   \n24108     5    1  51.990823  5.154603  2.270476  61.933868  49.136837   \n\n          leq_25  leq_median     leq_75  ...  tonality_mean  tonality_var  \\\n0      63.354370   64.548130  65.572620  ...        0.05675      0.001730   \n1      63.354370   64.548130  65.572620  ...        0.05675      0.001730   \n2      63.354370   64.548130  65.572620  ...        0.05675      0.001730   \n3      63.354370   64.548130  65.572620  ...        0.05675      0.001730   \n4      63.354370   64.548130  65.572620  ...        0.05675      0.001730   \n...          ...         ...        ...  ...            ...           ...   \n24104  50.202316   51.807796  53.696781  ...        0.06389      0.002687   \n24105  50.202316   51.807796  53.696781  ...        0.06389      0.002687   \n24106  50.202316   51.807796  53.696781  ...        0.06389      0.002687   \n24107  50.202316   51.807796  53.696781  ...        0.06389      0.002687   \n24108  50.202316   51.807796  53.696781  ...        0.06389      0.002687   \n\n       tonality_std  tonality_max  tonality_10  tonality_25  tonality_median  \\\n0          0.041700      0.185510          0.0     0.028230         0.053160   \n1          0.041700      0.185510          0.0     0.028230         0.053160   \n2          0.041700      0.185510          0.0     0.028230         0.053160   \n3          0.041700      0.185510          0.0     0.028230         0.053160   \n4          0.041700      0.185510          0.0     0.028230         0.053160   \n...             ...           ...          ...          ...              ...   \n24104      0.051854      0.562305          0.0     0.028721         0.058621   \n24105      0.051854      0.562305          0.0     0.028721         0.058621   \n24106      0.051854      0.562305          0.0     0.028721         0.058621   \n24107      0.051854      0.562305          0.0     0.028721         0.058621   \n24108      0.051854      0.562305          0.0     0.028721         0.058621   \n\n       tonality_75  tonality_90  tonality_10-tonality_90  \n0         0.080160     0.110410                 0.110410  \n1         0.080160     0.110410                 0.110410  \n2         0.080160     0.110410                 0.110410  \n3         0.080160     0.110410                 0.110410  \n4         0.080160     0.110410                 0.110410  \n...            ...          ...                      ...  \n24104     0.093968     0.126624                 0.126624  \n24105     0.093968     0.126624                 0.126624  \n24106     0.093968     0.126624                 0.126624  \n24107     0.093968     0.126624                 0.126624  \n24108     0.093968     0.126624                 0.126624  \n\n[24109 rows x 62 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>声音类别</th>\n      <th>吵闹度</th>\n      <th>leq_mean</th>\n      <th>leq_var</th>\n      <th>leq_std</th>\n      <th>leq_max</th>\n      <th>leq_10</th>\n      <th>leq_25</th>\n      <th>leq_median</th>\n      <th>leq_75</th>\n      <th>...</th>\n      <th>tonality_mean</th>\n      <th>tonality_var</th>\n      <th>tonality_std</th>\n      <th>tonality_max</th>\n      <th>tonality_10</th>\n      <th>tonality_25</th>\n      <th>tonality_median</th>\n      <th>tonality_75</th>\n      <th>tonality_90</th>\n      <th>tonality_10-tonality_90</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>4</td>\n      <td>64.666450</td>\n      <td>2.449020</td>\n      <td>1.565390</td>\n      <td>68.816510</td>\n      <td>62.728380</td>\n      <td>63.354370</td>\n      <td>64.548130</td>\n      <td>65.572620</td>\n      <td>...</td>\n      <td>0.05675</td>\n      <td>0.001730</td>\n      <td>0.041700</td>\n      <td>0.185510</td>\n      <td>0.0</td>\n      <td>0.028230</td>\n      <td>0.053160</td>\n      <td>0.080160</td>\n      <td>0.110410</td>\n      <td>0.110410</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4</td>\n      <td>64.666450</td>\n      <td>2.449020</td>\n      <td>1.565390</td>\n      <td>68.816510</td>\n      <td>62.728380</td>\n      <td>63.354370</td>\n      <td>64.548130</td>\n      <td>65.572620</td>\n      <td>...</td>\n      <td>0.05675</td>\n      <td>0.001730</td>\n      <td>0.041700</td>\n      <td>0.185510</td>\n      <td>0.0</td>\n      <td>0.028230</td>\n      <td>0.053160</td>\n      <td>0.080160</td>\n      <td>0.110410</td>\n      <td>0.110410</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>64.666450</td>\n      <td>2.449020</td>\n      <td>1.565390</td>\n      <td>68.816510</td>\n      <td>62.728380</td>\n      <td>63.354370</td>\n      <td>64.548130</td>\n      <td>65.572620</td>\n      <td>...</td>\n      <td>0.05675</td>\n      <td>0.001730</td>\n      <td>0.041700</td>\n      <td>0.185510</td>\n      <td>0.0</td>\n      <td>0.028230</td>\n      <td>0.053160</td>\n      <td>0.080160</td>\n      <td>0.110410</td>\n      <td>0.110410</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>64.666450</td>\n      <td>2.449020</td>\n      <td>1.565390</td>\n      <td>68.816510</td>\n      <td>62.728380</td>\n      <td>63.354370</td>\n      <td>64.548130</td>\n      <td>65.572620</td>\n      <td>...</td>\n      <td>0.05675</td>\n      <td>0.001730</td>\n      <td>0.041700</td>\n      <td>0.185510</td>\n      <td>0.0</td>\n      <td>0.028230</td>\n      <td>0.053160</td>\n      <td>0.080160</td>\n      <td>0.110410</td>\n      <td>0.110410</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>7</td>\n      <td>64.666450</td>\n      <td>2.449020</td>\n      <td>1.565390</td>\n      <td>68.816510</td>\n      <td>62.728380</td>\n      <td>63.354370</td>\n      <td>64.548130</td>\n      <td>65.572620</td>\n      <td>...</td>\n      <td>0.05675</td>\n      <td>0.001730</td>\n      <td>0.041700</td>\n      <td>0.185510</td>\n      <td>0.0</td>\n      <td>0.028230</td>\n      <td>0.053160</td>\n      <td>0.080160</td>\n      <td>0.110410</td>\n      <td>0.110410</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24104</th>\n      <td>5</td>\n      <td>2</td>\n      <td>51.990823</td>\n      <td>5.154603</td>\n      <td>2.270476</td>\n      <td>61.933868</td>\n      <td>49.136837</td>\n      <td>50.202316</td>\n      <td>51.807796</td>\n      <td>53.696781</td>\n      <td>...</td>\n      <td>0.06389</td>\n      <td>0.002687</td>\n      <td>0.051854</td>\n      <td>0.562305</td>\n      <td>0.0</td>\n      <td>0.028721</td>\n      <td>0.058621</td>\n      <td>0.093968</td>\n      <td>0.126624</td>\n      <td>0.126624</td>\n    </tr>\n    <tr>\n      <th>24105</th>\n      <td>5</td>\n      <td>2</td>\n      <td>51.990823</td>\n      <td>5.154603</td>\n      <td>2.270476</td>\n      <td>61.933868</td>\n      <td>49.136837</td>\n      <td>50.202316</td>\n      <td>51.807796</td>\n      <td>53.696781</td>\n      <td>...</td>\n      <td>0.06389</td>\n      <td>0.002687</td>\n      <td>0.051854</td>\n      <td>0.562305</td>\n      <td>0.0</td>\n      <td>0.028721</td>\n      <td>0.058621</td>\n      <td>0.093968</td>\n      <td>0.126624</td>\n      <td>0.126624</td>\n    </tr>\n    <tr>\n      <th>24106</th>\n      <td>5</td>\n      <td>3</td>\n      <td>51.990823</td>\n      <td>5.154603</td>\n      <td>2.270476</td>\n      <td>61.933868</td>\n      <td>49.136837</td>\n      <td>50.202316</td>\n      <td>51.807796</td>\n      <td>53.696781</td>\n      <td>...</td>\n      <td>0.06389</td>\n      <td>0.002687</td>\n      <td>0.051854</td>\n      <td>0.562305</td>\n      <td>0.0</td>\n      <td>0.028721</td>\n      <td>0.058621</td>\n      <td>0.093968</td>\n      <td>0.126624</td>\n      <td>0.126624</td>\n    </tr>\n    <tr>\n      <th>24107</th>\n      <td>5</td>\n      <td>5</td>\n      <td>51.990823</td>\n      <td>5.154603</td>\n      <td>2.270476</td>\n      <td>61.933868</td>\n      <td>49.136837</td>\n      <td>50.202316</td>\n      <td>51.807796</td>\n      <td>53.696781</td>\n      <td>...</td>\n      <td>0.06389</td>\n      <td>0.002687</td>\n      <td>0.051854</td>\n      <td>0.562305</td>\n      <td>0.0</td>\n      <td>0.028721</td>\n      <td>0.058621</td>\n      <td>0.093968</td>\n      <td>0.126624</td>\n      <td>0.126624</td>\n    </tr>\n    <tr>\n      <th>24108</th>\n      <td>5</td>\n      <td>1</td>\n      <td>51.990823</td>\n      <td>5.154603</td>\n      <td>2.270476</td>\n      <td>61.933868</td>\n      <td>49.136837</td>\n      <td>50.202316</td>\n      <td>51.807796</td>\n      <td>53.696781</td>\n      <td>...</td>\n      <td>0.06389</td>\n      <td>0.002687</td>\n      <td>0.051854</td>\n      <td>0.562305</td>\n      <td>0.0</td>\n      <td>0.028721</td>\n      <td>0.058621</td>\n      <td>0.093968</td>\n      <td>0.126624</td>\n      <td>0.126624</td>\n    </tr>\n  </tbody>\n</table>\n<p>24109 rows × 62 columns</p>\n</div>"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_83 = pd.read_csv(r'./input/use_data_83.csv')\n",
    "feature_test = pd.read_csv(r'./input/kyllin_features.csv')\n",
    "# dataset_all = pd.read_csv(r'./input/all_data.csv')\n",
    "dataset_83"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "# column_36 = ['leq_mean', 'leq_std', 'leq_25', 'leq_median',\n",
    "#             'leq_75', 'leq_10_90', 'loudness_mean', 'loudness_std',\n",
    "#             'loudness_25', 'loudness_median', 'loudness_75',\n",
    "#             'loudness_10_90', 'roughness_mean', 'roughness_std',\n",
    "#             'roughness_25', 'roughness_median', 'roughness_75',\n",
    "#             'roughness_10_90', 'sharpness_mean', 'sharpness_std',\n",
    "#             'sharpness_25', 'sharpness_median', 'sharpness_75',\n",
    "#             'sharpness_10_90', 'fluct_mean', 'fluct_std', 'fluct_25',\n",
    "#             'fluct_median', 'fluct_75', 'fluct_10_90', 'tonality_mean',\n",
    "#             'tonality_std', 'tonality_25', 'tonality_median', 'tonality_75',\n",
    "#             'tonality_10_90']\n",
    "\n",
    "# y = dataset_83['吵闹度']\n",
    "# X_primary = dataset_83[column_36]\n",
    "# X = feature_normalize(X_primary)\n",
    "# X_test = feature_normalize(feature_test[column_36])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "y = dataset_83['吵闹度']\n",
    "X_primary = dataset_83[column_36]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py:359: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "DecisionTreeRegressor(criterion='mse')"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeRegressor(criterion='mse', splitter='best')\n",
    "# dtree.fit(X, y)\n",
    "dtree.fit(X_primary, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "# y_test = dtree.predict(X_test)\n",
    "# y_test = dtree.predict(feature_test[column_36])\n",
    "# y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "# test_out = pd.DataFrame()\n",
    "# test_out['name'] = feature_test['name']\n",
    "# test_out['score'] = y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "# test_out.to_csv(r'./output/test.csv', index=False, encoding='utf_8_sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "     leq_mean   leq_std     leq_25  leq_median     leq_75  leq_10-leq_90  \\\n0   55.232130  5.319207  50.331184   56.141373  59.358688      14.299032   \n1   50.990445  3.790288  47.271271   52.034287  54.249622       9.581163   \n2   55.732233  2.579936  53.848297   55.836800  57.593357       6.445042   \n3   50.850839  3.243968  48.294189   50.739494  52.977394       7.861456   \n4   50.480544  4.658396  47.364754   50.697357  53.007847      10.091568   \n..        ...       ...        ...         ...        ...            ...   \n70  51.684594  2.950931  49.122250   51.338657  53.338589       7.694008   \n71  56.086409  5.981590  50.723267   56.433147  59.950764      16.290859   \n72  50.047239  2.401969  48.324600   49.654362  51.642471       6.221943   \n73  50.874526  2.089157  49.593983   50.240971  51.657730       4.288685   \n74  51.327230  1.785935  49.961189   51.132454  52.213837       3.964472   \n\n    loudness_mean  loudness_std  loudness_25  loudness_median  ...  fluct_25  \\\n0        6.822645      2.222474        4.948            6.616  ...  0.007573   \n1        5.447094      0.944530        4.642            5.502  ...  0.004376   \n2        7.831393      1.859701        6.400            7.247  ...  0.091772   \n3        5.997294      1.182890        5.152            5.897  ...  0.012791   \n4        5.412632      2.033547        4.196            5.096  ...  0.009835   \n..            ...           ...          ...              ...  ...       ...   \n70       6.144695      1.181480        5.224            5.905  ...  0.004002   \n71       7.688258      2.892483        5.349            7.263  ...  0.006362   \n72       5.904786      1.073166        5.273            5.686  ...  0.006031   \n73       6.420369      0.943794        5.854            6.200  ...  0.003055   \n74       6.673368      0.785199        6.077            6.583  ...  0.002669   \n\n    fluct_median  fluct_75  fluct_10-fluct_90  tonality_mean  tonality_std  \\\n0       0.011714  0.014903           0.016429       0.090862      0.062262   \n1       0.006319  0.013831           0.019906       0.053997      0.047247   \n2       0.123620  0.150747           0.135921       0.044188      0.041625   \n3       0.018036  0.023764           0.026002       0.057085      0.046005   \n4       0.014763  0.027707           0.046409       0.060576      0.053735   \n..           ...       ...                ...            ...           ...   \n70      0.010360  0.022415           0.032302       0.118365      0.061495   \n71      0.009434  0.012003           0.017800       0.063056      0.048654   \n72      0.014525  0.032093           0.042514       0.040851      0.040539   \n73      0.005694  0.010639           0.031608       0.041429      0.038538   \n74      0.004922  0.014560           0.026338       0.062299      0.050873   \n\n    tonality_25  tonality_median  tonality_75  tonality_10-tonality_90  \n0      0.046919         0.084511     0.128971                 0.176758  \n1      0.000000         0.050423     0.085405                 0.118994  \n2      0.000000         0.039642     0.071143                 0.102402  \n3      0.023572         0.050706     0.084524                 0.119571  \n4      0.015611         0.052863     0.090540                 0.131772  \n..          ...              ...          ...                      ...  \n70     0.077229         0.106951     0.144127                 0.136776  \n71     0.024658         0.057933     0.093155                 0.128203  \n72     0.000000         0.036629     0.067197                 0.097571  \n73     0.000000         0.039179     0.065948                 0.091092  \n74     0.022004         0.057294     0.093313                 0.130287  \n\n[75 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>leq_mean</th>\n      <th>leq_std</th>\n      <th>leq_25</th>\n      <th>leq_median</th>\n      <th>leq_75</th>\n      <th>leq_10-leq_90</th>\n      <th>loudness_mean</th>\n      <th>loudness_std</th>\n      <th>loudness_25</th>\n      <th>loudness_median</th>\n      <th>...</th>\n      <th>fluct_25</th>\n      <th>fluct_median</th>\n      <th>fluct_75</th>\n      <th>fluct_10-fluct_90</th>\n      <th>tonality_mean</th>\n      <th>tonality_std</th>\n      <th>tonality_25</th>\n      <th>tonality_median</th>\n      <th>tonality_75</th>\n      <th>tonality_10-tonality_90</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55.232130</td>\n      <td>5.319207</td>\n      <td>50.331184</td>\n      <td>56.141373</td>\n      <td>59.358688</td>\n      <td>14.299032</td>\n      <td>6.822645</td>\n      <td>2.222474</td>\n      <td>4.948</td>\n      <td>6.616</td>\n      <td>...</td>\n      <td>0.007573</td>\n      <td>0.011714</td>\n      <td>0.014903</td>\n      <td>0.016429</td>\n      <td>0.090862</td>\n      <td>0.062262</td>\n      <td>0.046919</td>\n      <td>0.084511</td>\n      <td>0.128971</td>\n      <td>0.176758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50.990445</td>\n      <td>3.790288</td>\n      <td>47.271271</td>\n      <td>52.034287</td>\n      <td>54.249622</td>\n      <td>9.581163</td>\n      <td>5.447094</td>\n      <td>0.944530</td>\n      <td>4.642</td>\n      <td>5.502</td>\n      <td>...</td>\n      <td>0.004376</td>\n      <td>0.006319</td>\n      <td>0.013831</td>\n      <td>0.019906</td>\n      <td>0.053997</td>\n      <td>0.047247</td>\n      <td>0.000000</td>\n      <td>0.050423</td>\n      <td>0.085405</td>\n      <td>0.118994</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55.732233</td>\n      <td>2.579936</td>\n      <td>53.848297</td>\n      <td>55.836800</td>\n      <td>57.593357</td>\n      <td>6.445042</td>\n      <td>7.831393</td>\n      <td>1.859701</td>\n      <td>6.400</td>\n      <td>7.247</td>\n      <td>...</td>\n      <td>0.091772</td>\n      <td>0.123620</td>\n      <td>0.150747</td>\n      <td>0.135921</td>\n      <td>0.044188</td>\n      <td>0.041625</td>\n      <td>0.000000</td>\n      <td>0.039642</td>\n      <td>0.071143</td>\n      <td>0.102402</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50.850839</td>\n      <td>3.243968</td>\n      <td>48.294189</td>\n      <td>50.739494</td>\n      <td>52.977394</td>\n      <td>7.861456</td>\n      <td>5.997294</td>\n      <td>1.182890</td>\n      <td>5.152</td>\n      <td>5.897</td>\n      <td>...</td>\n      <td>0.012791</td>\n      <td>0.018036</td>\n      <td>0.023764</td>\n      <td>0.026002</td>\n      <td>0.057085</td>\n      <td>0.046005</td>\n      <td>0.023572</td>\n      <td>0.050706</td>\n      <td>0.084524</td>\n      <td>0.119571</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50.480544</td>\n      <td>4.658396</td>\n      <td>47.364754</td>\n      <td>50.697357</td>\n      <td>53.007847</td>\n      <td>10.091568</td>\n      <td>5.412632</td>\n      <td>2.033547</td>\n      <td>4.196</td>\n      <td>5.096</td>\n      <td>...</td>\n      <td>0.009835</td>\n      <td>0.014763</td>\n      <td>0.027707</td>\n      <td>0.046409</td>\n      <td>0.060576</td>\n      <td>0.053735</td>\n      <td>0.015611</td>\n      <td>0.052863</td>\n      <td>0.090540</td>\n      <td>0.131772</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>51.684594</td>\n      <td>2.950931</td>\n      <td>49.122250</td>\n      <td>51.338657</td>\n      <td>53.338589</td>\n      <td>7.694008</td>\n      <td>6.144695</td>\n      <td>1.181480</td>\n      <td>5.224</td>\n      <td>5.905</td>\n      <td>...</td>\n      <td>0.004002</td>\n      <td>0.010360</td>\n      <td>0.022415</td>\n      <td>0.032302</td>\n      <td>0.118365</td>\n      <td>0.061495</td>\n      <td>0.077229</td>\n      <td>0.106951</td>\n      <td>0.144127</td>\n      <td>0.136776</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>56.086409</td>\n      <td>5.981590</td>\n      <td>50.723267</td>\n      <td>56.433147</td>\n      <td>59.950764</td>\n      <td>16.290859</td>\n      <td>7.688258</td>\n      <td>2.892483</td>\n      <td>5.349</td>\n      <td>7.263</td>\n      <td>...</td>\n      <td>0.006362</td>\n      <td>0.009434</td>\n      <td>0.012003</td>\n      <td>0.017800</td>\n      <td>0.063056</td>\n      <td>0.048654</td>\n      <td>0.024658</td>\n      <td>0.057933</td>\n      <td>0.093155</td>\n      <td>0.128203</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>50.047239</td>\n      <td>2.401969</td>\n      <td>48.324600</td>\n      <td>49.654362</td>\n      <td>51.642471</td>\n      <td>6.221943</td>\n      <td>5.904786</td>\n      <td>1.073166</td>\n      <td>5.273</td>\n      <td>5.686</td>\n      <td>...</td>\n      <td>0.006031</td>\n      <td>0.014525</td>\n      <td>0.032093</td>\n      <td>0.042514</td>\n      <td>0.040851</td>\n      <td>0.040539</td>\n      <td>0.000000</td>\n      <td>0.036629</td>\n      <td>0.067197</td>\n      <td>0.097571</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>50.874526</td>\n      <td>2.089157</td>\n      <td>49.593983</td>\n      <td>50.240971</td>\n      <td>51.657730</td>\n      <td>4.288685</td>\n      <td>6.420369</td>\n      <td>0.943794</td>\n      <td>5.854</td>\n      <td>6.200</td>\n      <td>...</td>\n      <td>0.003055</td>\n      <td>0.005694</td>\n      <td>0.010639</td>\n      <td>0.031608</td>\n      <td>0.041429</td>\n      <td>0.038538</td>\n      <td>0.000000</td>\n      <td>0.039179</td>\n      <td>0.065948</td>\n      <td>0.091092</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>51.327230</td>\n      <td>1.785935</td>\n      <td>49.961189</td>\n      <td>51.132454</td>\n      <td>52.213837</td>\n      <td>3.964472</td>\n      <td>6.673368</td>\n      <td>0.785199</td>\n      <td>6.077</td>\n      <td>6.583</td>\n      <td>...</td>\n      <td>0.002669</td>\n      <td>0.004922</td>\n      <td>0.014560</td>\n      <td>0.026338</td>\n      <td>0.062299</td>\n      <td>0.050873</td>\n      <td>0.022004</td>\n      <td>0.057294</td>\n      <td>0.093313</td>\n      <td>0.130287</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_yf = pd.read_csv(r'./test/杨凡1.csv')\n",
    "predict_yf_X = test_yf[column_36]\n",
    "predict_yf_X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.70901639, 5.91803279, 2.7037037 , 5.91803279, 5.92622951,\n       2.70901639, 5.92622951, 2.7037037 , 2.7037037 , 6.07786885,\n       3.5       , 2.7037037 , 2.7037037 , 5.91803279, 2.70901639,\n       6.07786885, 5.99593496, 5.91803279, 2.70901639, 6.07786885,\n       6.04098361, 5.92622951, 2.71020408, 6.07786885, 5.92622951,\n       6.04098361, 6.04098361, 2.70901639, 5.91803279, 6.04098361,\n       2.70901639, 5.91803279, 6.07786885, 2.70901639, 2.70901639,\n       2.66393443, 2.70901639, 2.70901639, 2.70901639, 2.70901639,\n       2.70901639, 2.89344262, 2.70901639, 2.70901639, 2.70901639,\n       2.70901639, 2.70901639, 2.70901639, 3.71311475, 6.04098361,\n       6.04098361, 5.99593496, 5.91803279, 3.79918033, 2.7037037 ,\n       5.92622951, 2.70901639, 5.91803279, 3.71311475, 6.04098361,\n       5.91803279, 5.91803279, 6.04098361, 3.71311475, 6.70491803,\n       5.92622951, 2.70901639, 6.04098361, 2.70901639, 6.04098361,\n       2.70901639, 2.70901639, 5.91803279, 2.7037037 , 2.70901639])"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_yf_y = dtree.predict(predict_yf_X)\n",
    "predict_yf_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6133333333333333"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_class, true_class = return_predict_and_true_class(predict_yf_y, test_yf['noise_score'].values)\n",
    "\n",
    "acc = accuracy(pre_class, true_class)\n",
    "acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "contract = pd.DataFrame()\n",
    "contract['predict'] = pre_class\n",
    "contract['predict_score'] = predict_yf_y\n",
    "contract['true'] = true_class\n",
    "contract['true_score'] = test_yf['noise_score'].values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "data": {
      "text/plain": "    predict  predict_score  true  true_score\n0         4       2.709016     4           3\n1         1       5.918033     4           4\n2         4       2.703704     4           2\n3         1       5.918033     1           7\n4         2       5.926230     2           5\n..      ...            ...   ...         ...\n70        4       2.709016     4           4\n71        4       2.709016     4           3\n72        1       5.918033     4           3\n73        4       2.703704     4           3\n74        4       2.709016     4           4\n\n[75 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predict</th>\n      <th>predict_score</th>\n      <th>true</th>\n      <th>true_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>2.709016</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>5.918033</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>2.703704</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>5.918033</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>5.926230</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>4</td>\n      <td>2.709016</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>4</td>\n      <td>2.709016</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>1</td>\n      <td>5.918033</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>4</td>\n      <td>2.703704</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>4</td>\n      <td>2.709016</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contract"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
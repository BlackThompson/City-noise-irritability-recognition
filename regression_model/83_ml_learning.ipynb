{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(    order  leq_mean  leq_std    leq_25  leq_median    leq_75  leq_10-leq_90  \\\n 0       1  64.66645  1.56539  63.35437    64.54813  65.57262        4.14383   \n 1       2  64.46865  2.12706  63.42707    64.53042  65.95546        5.36740   \n 2       3  62.65053  2.71845  60.37409    62.20640  64.26367        7.00544   \n 3       4  64.14055  2.67668  62.63100    63.85893  65.68914        7.07971   \n 4       5  64.21175  2.65563  61.74495    63.99769  66.86936        6.54266   \n ..    ...       ...      ...       ...         ...       ...            ...   \n 78     79  63.60349  0.54465  63.24110    63.52017  63.91679        1.32561   \n 79     80  62.72917  4.30253  59.32059    62.03001  65.98382       11.82343   \n 80     81  63.67776  3.05028  60.83388    63.39218  66.66382        8.16993   \n 81     82  63.29483  2.21022  61.46640    63.55796  64.93642        5.80945   \n 82     83  63.90276  1.58277  62.72562    63.50389  65.10709        4.15885   \n \n     loudness_mean  loudness_std  loudness_25  ...  fluct_25  fluct_median  \\\n 0        17.75490       1.86917      16.2550  ...   0.00783       0.01473   \n 1        15.93369       2.01787      14.9885  ...   0.00680       0.00986   \n 2        14.61514       2.42780      12.6235  ...   0.00583       0.00735   \n 3        14.42197       2.36871      12.9970  ...   0.05699       0.06786   \n 4        16.29315       3.11429      13.5190  ...   0.00847       0.01029   \n ..            ...           ...          ...  ...       ...           ...   \n 78       14.84529       0.83521      14.1290  ...   0.01001       0.01500   \n 79       14.62678       4.56900      11.1720  ...   0.01008       0.01594   \n 80       14.71222       2.29281      13.0970  ...   0.00919       0.01107   \n 81       13.90514       2.09026      12.4460  ...   0.01481       0.02182   \n 82       16.14553       1.19750      15.2080  ...   0.00794       0.00967   \n \n     fluct_75  fluct_10-fluct_90  tonality_mean  tonality_std  tonality_25  \\\n 0    0.01984            0.06271        0.05675       0.04170      0.02823   \n 1    0.01506            0.06290        0.07857       0.03860      0.05377   \n 2    0.03699            0.07551        0.03378       0.02960      0.00000   \n 3    0.07799            0.04313        0.07578       0.05435      0.03825   \n 4    0.02310            0.06698        0.03665       0.05147      0.00000   \n ..       ...                ...            ...           ...          ...   \n 78   0.02036            0.07177        0.06866       0.03105      0.05248   \n 79   0.02446            0.05440        0.02584       0.02711      0.00000   \n 80   0.02718            0.06224        0.03463       0.02767      0.00000   \n 81   0.03174            0.06586        0.07918       0.05806      0.03147   \n 82   0.02265            0.06929        0.02446       0.02661      0.00000   \n \n     tonality_median  tonality_75  tonality_10-tonality_90  \n 0           0.05316      0.08016                  0.11041  \n 1           0.07142      0.09646                  0.09131  \n 2           0.03544      0.05589                  0.07545  \n 3           0.06447      0.11175                  0.14294  \n 4           0.02797      0.05282                  0.08091  \n ..              ...          ...                      ...  \n 78          0.07045      0.08739                  0.08315  \n 79          0.02206      0.04169                  0.06150  \n 80          0.03425      0.05437                  0.07128  \n 81          0.07278      0.12333                  0.14858  \n 82          0.02622      0.04394                  0.05603  \n \n [83 rows x 37 columns],\n 0     5.95492\n 1     4.87705\n 2     4.53279\n 3     4.97951\n 4     6.12295\n        ...   \n 78    3.62705\n 79    7.57377\n 80    4.37705\n 81    4.21311\n 82    5.40164\n Name: score, Length: 83, dtype: float64)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入弹性网\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "column_36 = ['Leq_mean', 'Leq_std', 'Leq_25', 'Leq_median',\n",
    "             'Leq_75', 'Leq_10-Leq_90', 'Loudness_mean', 'Loudness_std',\n",
    "             'Loudness_25', 'Loudness_median', 'Loudness_75',\n",
    "             'Loudness_10-Loudness_90', 'Roughness_mean', 'Roughness_std',\n",
    "             'Roughness_25', 'Roughness_median', 'Roughness_75',\n",
    "             'Roughness_10-Roughness_90', 'Sharpness_mean', 'Sharpness_std',\n",
    "             'Sharpness_25', 'Sharpness_median', 'Sharpness_75',\n",
    "             'Sharpness_10-Sharpness_90', 'Fluct_mean', 'Fluct_std', 'Fluct_25',\n",
    "             'Fluct_median', 'Fluct_75', 'Fluct_10-Fluct_90', 'Tonality_mean',\n",
    "             'Tonality_std', 'Tonality_25', 'Tonality_median', 'Tonality_75',\n",
    "             'Tonality_10-Tonality_90']\n",
    "\n",
    "# # 用于构造交互项的列\n",
    "column_interaction = ['Leq_mean', 'Leq_std', 'Loudness_mean', 'Loudness_std', 'Roughness_mean', 'Roughness_std',\n",
    "                      'Sharpness_mean', 'Sharpness_std', 'Fluct_mean', 'Fluct_std', 'Tonality_mean', 'Tonality_std']\n",
    "\n",
    "# 转化为小写\n",
    "for i in range(len(column_36)):\n",
    "    column_36[i] = column_36[i].lower()\n",
    "\n",
    "# 增加了排序列\n",
    "column_36_order = copy.deepcopy(column_36)\n",
    "column_36_order.insert(0, 'order')\n",
    "\n",
    "# 读入数据\n",
    "path = r'.\\input\\feature_83.csv'\n",
    "data_83 = pd.read_csv(path)\n",
    "# 所有列\n",
    "columns = data_83.columns\n",
    "y_column = columns[-1]\n",
    "\n",
    "data_x = data_83[column_36_order]\n",
    "data_y = data_83[y_column]\n",
    "data_x, data_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['order',\n 'leq_mean',\n 'leq_std',\n 'leq_25',\n 'leq_median',\n 'leq_75',\n 'leq_10-leq_90',\n 'loudness_mean',\n 'loudness_std',\n 'loudness_25',\n 'loudness_median',\n 'loudness_75',\n 'loudness_10-loudness_90',\n 'roughness_mean',\n 'roughness_std',\n 'roughness_25',\n 'roughness_median',\n 'roughness_75',\n 'roughness_10-roughness_90',\n 'sharpness_mean',\n 'sharpness_std',\n 'sharpness_25',\n 'sharpness_median',\n 'sharpness_75',\n 'sharpness_10-sharpness_90',\n 'fluct_mean',\n 'fluct_std',\n 'fluct_25',\n 'fluct_median',\n 'fluct_75',\n 'fluct_10-fluct_90',\n 'tonality_mean',\n 'tonality_std',\n 'tonality_25',\n 'tonality_median',\n 'tonality_75',\n 'tonality_10-tonality_90']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_36_order"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.23556489964835936, 0.2721281515358761)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打乱数据,训练测试8:2\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=.1, random_state=0)\n",
    "\n",
    "# 训练 ElasticNet\n",
    "alpha = 0.1\n",
    "enet = ElasticNet(alpha=alpha, l1_ratio=0.1, normalize=True)\n",
    "# enet = make_pipeline(StandardScaler(), ElasticNet())\n",
    "enet.fit(x_train[column_36], y_train)\n",
    "\n",
    "# 验证\n",
    "predict = enet.predict(x_test[column_36])\n",
    "enet.score(x_train[column_36], y_train), enet.score(x_test[column_36], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(    order  leq_mean  leq_std  loudness_mean  loudness_std  roughness_mean  \\\n 0       1  64.66645  1.56539       17.75490       1.86917         2.17955   \n 1       2  64.46865  2.12706       15.93369       2.01787         2.34253   \n 2       3  62.65053  2.71845       14.61514       2.42780         2.02092   \n 3       4  64.14055  2.67668       14.42197       2.36871         1.80561   \n 4       5  64.21175  2.65563       16.29315       3.11429         2.25994   \n ..    ...       ...      ...            ...           ...             ...   \n 78     79  63.60349  0.54465       14.84529       0.83521         2.06608   \n 79     80  62.72917  4.30253       14.62678       4.56900         2.74957   \n 80     81  63.67776  3.05028       14.71222       2.29281         2.10886   \n 81     82  63.29483  2.21022       13.90514       2.09026         2.02066   \n 82     83  63.90276  1.58277       16.14553       1.19750         2.11045   \n \n     roughness_std  sharpness_mean  sharpness_std  fluct_mean  fluct_std  \\\n 0         0.24350         3.41830        0.21886     0.02187    0.02207   \n 1         0.29453         2.59361        0.14856     0.01954    0.02314   \n 2         0.25950         2.43511        0.14823     0.02493    0.03142   \n 3         0.26894         2.26955        0.26197     0.06619    0.02455   \n 4         0.29018         2.68957        0.23626     0.02198    0.02504   \n ..            ...             ...            ...         ...        ...   \n 78        0.17977         2.17046        0.10647     0.02524    0.02635   \n 79        0.74990         2.72663        0.33177     0.02308    0.01962   \n 80        0.28123         2.35564        0.28395     0.02443    0.02684   \n 81        0.38707         2.11685        0.22325     0.02901    0.02317   \n 82        0.18255         2.56731        0.13400     0.02241    0.02649   \n \n     tonality_mean  tonality_std  \n 0         0.05675       0.04170  \n 1         0.07857       0.03860  \n 2         0.03378       0.02960  \n 3         0.07578       0.05435  \n 4         0.03665       0.05147  \n ..            ...           ...  \n 78        0.06866       0.03105  \n 79        0.02584       0.02711  \n 80        0.03463       0.02767  \n 81        0.07918       0.05806  \n 82        0.02446       0.02661  \n \n [83 rows x 13 columns],\n 0     5.95492\n 1     4.87705\n 2     4.53279\n 3     4.97951\n 4     6.12295\n        ...   \n 78    3.62705\n 79    7.57377\n 80    4.37705\n 81    4.21311\n 82    5.40164\n Name: score, Length: 83, dtype: float64)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入弹性网\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# # 用于构造交互项的列\n",
    "column_interaction = ['Leq_mean', 'Leq_std', 'Loudness_mean', 'Loudness_std', 'Roughness_mean', 'Roughness_std',\n",
    "                      'Sharpness_mean', 'Sharpness_std', 'Fluct_mean', 'Fluct_std', 'Tonality_mean', 'Tonality_std']\n",
    "\n",
    "# 转化为小写\n",
    "for i in range(len(column_interaction)):\n",
    "    column_interaction[i] = column_interaction[i].lower()\n",
    "\n",
    "# 增加了排序列\n",
    "column_interaction_order = copy.deepcopy(column_interaction)\n",
    "column_interaction_order.insert(0, 'order')\n",
    "\n",
    "# 读入数据\n",
    "path = r'.\\input\\feature_83.csv'\n",
    "data_83 = pd.read_csv(path)\n",
    "# 所有列\n",
    "columns = data_83.columns\n",
    "y_column = columns[-1]\n",
    "\n",
    "data_x = data_83[column_interaction_order]\n",
    "data_y = data_83[y_column]\n",
    "data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3.900000e+01, 6.388686e+01, 1.340000e+00, ..., 2.643000e-02,\n        1.641000e-02, 2.153000e-02],\n       [3.000000e+00, 6.265053e+01, 2.718450e+00, ..., 3.142000e-02,\n        3.378000e-02, 2.960000e-02],\n       [5.600000e+01, 6.430822e+01, 2.615110e+00, ..., 2.283000e-02,\n        3.827000e-02, 3.506000e-02],\n       ...,\n       [6.500000e+01, 6.491698e+01, 8.952200e-01, ..., 1.990000e-02,\n        2.435300e-01, 5.971000e-02],\n       [4.800000e+01, 6.303810e+01, 1.120860e+00, ..., 2.132000e-02,\n        2.687000e-02, 2.607000e-02],\n       [4.500000e+01, 6.162466e+01, 5.737750e+00, ..., 1.056400e-01,\n        6.689000e-02, 3.958000e-02]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打乱数据,训练测试9:1\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=.05, random_state=0)\n",
    "x_train_array = x_train.values\n",
    "x_test_array = x_test.values\n",
    "x_train_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3)\n",
    "x_train_array = poly.fit_transform(x_train_array)\n",
    "x_test_array = poly.fit_transform(x_test_array)\n",
    "y_train_array = y_train.values\n",
    "y_test_array = y_test.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([5.12536382, 5.11980908, 5.05091927, 4.49012834, 5.34128505]),\n array([5.4959 , 4.93033, 3.7623 , 3.7541 , 5.28279]))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练 ElasticNet\n",
    "alpha = 0.1\n",
    "enet = ElasticNet(alpha=alpha, l1_ratio=0.1, normalize=True)\n",
    "# enet = make_pipeline(StandardScaler(), ElasticNet())\n",
    "enet.fit(x_train_array, y_train_array)\n",
    "\n",
    "# 验证\n",
    "predict = enet.predict(x_test_array)\n",
    "enet.score(x_train_array, y_train_array), enet.score(x_test_array, y_test_array)\n",
    "predict, y_test_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}